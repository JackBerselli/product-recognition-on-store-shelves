{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_imgs = ['0', '1', '11', '19', '24', '25', '26']\n",
    "train_imgs = ['e1.png', 'e2.png', 'e3.png', 'e4.png', 'e5.png']\n",
    "true_imgs = {\n",
    "    'e1.png':{'0','11'},\n",
    "    'e2.png':{'24','25','26'},\n",
    "    'e3.png':{'0','1','11'},\n",
    "    'e4.png':{'0','11','25','26'},\n",
    "    'e5.png':{'19','25'},\n",
    "}\n",
    "sorted_true_imgs = collections.OrderedDict(sorted(true_imgs.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOWE_COEFF = 0.5\n",
    "MIN_MATCH_COUNT = 30\n",
    "COLOR_T = 50\n",
    "COLORS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "\n",
    "for train_img in train_imgs:\n",
    "    \n",
    "    print('Scene: ' + train_img + '\\n')\n",
    "\n",
    "    train_file = 'scenes/' + train_img\n",
    "    \n",
    "    train = cv2.imread(train_file, 0)\n",
    "    train_bgr = cv2.imread(train_file)\n",
    "    \n",
    "    if COLORS == True:\n",
    "        train3 = cv2.cvtColor(train_bgr, cv2.COLOR_BGR2RGB)\n",
    "        train_rgb = np.zeros(train_bgr.shape, train_bgr.dtype)\n",
    "        for y in range(train3.shape[0]):\n",
    "            for x in range(train3.shape[1]):\n",
    "                for c in range(train3.shape[2]):\n",
    "                    train_rgb[y,x,c] = np.clip(0.5*train3[y,x,c], 0, 255)             \n",
    "    else:        \n",
    "        train_rgb = cv2.cvtColor(train, cv2.COLOR_GRAY2RGB)\n",
    "       \n",
    "    kp_train, des_train = sift.detectAndCompute(train, None)\n",
    "    \n",
    "    global_matches = {}\n",
    "    recognised = {}\n",
    "    \n",
    "    \n",
    "    for query_img in query_imgs:\n",
    "        \n",
    "        query_file = 'models/' + query_img + '.jpg'\n",
    "        query = cv2.imread(query_file, 0)\n",
    "\n",
    "        kp_query, des_query = sift.detectAndCompute(query, None)\n",
    "\n",
    "        bf = cv2.BFMatcher()\n",
    "\n",
    "        matches = bf.knnMatch(des_query, des_train, k=2)\n",
    "\n",
    "        good_matches = []\n",
    "        \n",
    "        for m, n in matches:\n",
    "            if m.distance < LOWE_COEFF * n.distance:\n",
    "                good_matches.append(m)\n",
    "              \n",
    "        global_matches[query_img] = (len(good_matches), good_matches, kp_query)\n",
    "    \n",
    "    sorted_global_matches = collections.OrderedDict(sorted(global_matches.items(), key=lambda item: item[1][0], reverse=True))\n",
    "    \n",
    "    \n",
    "    for k, v in sorted_global_matches.items():\n",
    "\n",
    "        if v[0] > MIN_MATCH_COUNT:\n",
    "            \n",
    "            query_file = 'models/' + k + '.jpg'\n",
    "            query_bgr = cv2.imread(query_file)\n",
    "            \n",
    "            src_pts = np.float32([v[2][m.queryIdx].pt for m in v[1]]).reshape(-1, 1, 2)\n",
    "            dst_pts = np.float32([kp_train[m.trainIdx].pt for m in v[1]]).reshape(-1, 1, 2)\n",
    "            M, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "            h, w, d = query_bgr.shape\n",
    "            pts = np.float32([[0,0],[0,h-1],[w-1,h-1],[w-1,0]]).reshape(-1,1,2)\n",
    "            dst = cv2.perspectiveTransform(pts, M)\n",
    "        \n",
    "            center = tuple((dst[0,0,i] + dst[1,0,i] + dst[2,0,i] + dst[3,0,i]) / 4 for i in (0,1))\n",
    "                                  \n",
    "            x_min = int(max((dst[0,0,0] + dst[1,0,0]) / 2, 0))\n",
    "            y_min = int(max((dst[0,0,1] + dst[3,0,1]) / 2, 0))\n",
    "            x_max = int(min((dst[2,0,0] + dst[3,0,0]) / 2, train.shape[1]))\n",
    "            y_max = int(min((dst[1,0,1] + dst[2,0,1]) / 2, train.shape[0]))\n",
    "\n",
    "            query_color = query_bgr.mean(axis=0).mean(axis=0)\n",
    "            train_crop = train_bgr[y_min:y_max,x_min:x_max]\n",
    "            train_color = train_crop.mean(axis=0).mean(axis=0)   \n",
    "            color_diff = np.sqrt(np.sum([value ** 2 for value in abs(query_color - train_color)]))\n",
    "            \n",
    "            temp = True \n",
    "            if color_diff < COLOR_T :\n",
    "                for r, corners in recognised.items():\n",
    "                    if center[0] > corners[0,0,0] and center[0] < corners[3,0,0]\\\n",
    "                    and center[1] > corners[0,0,1] and center[1] < corners[1,0,1]:\n",
    "                        temp = False\n",
    "                        break\n",
    "                if temp:\n",
    "                    recognised[k] = dst\n",
    "        \n",
    "    \n",
    "    for query_img in query_imgs:\n",
    "                     \n",
    "        total = int(query_img in recognised.keys())    \n",
    "        true_total = int(query_img in true_imgs[train_img])\n",
    "\n",
    "        print('Product ' + query_img + ' â€“ ' + str(total) + '/' + str(true_total) + ' instances found:')\n",
    "        \n",
    "        if total == 1:\n",
    "            dst = recognised[query_img]\n",
    "            center = tuple(int((dst[0,0,i] + dst[1,0,i] + dst[2,0,i] + dst[3,0,i]) / 4) for i in (0,1))\n",
    "            w = int(((dst[3,0,0] - dst[0,0,0]) + (dst[2,0,0] - dst[1,0,0])) /2)\n",
    "            h = int(((dst[1,0,1] - dst[0,0,1]) + (dst[2,0,1] - dst[3,0,1])) /2)\n",
    "            print('\\t' + 'Position: ' + str(center)\\\n",
    "                 + '\\t' + 'Width: ' + str(w)\\\n",
    "                 + '\\t' + 'Height: ' + str(h))\n",
    "            \n",
    "            \n",
    "    for k, v in recognised.items():\n",
    "\n",
    "        train_rgb = cv2.polylines(train_rgb, [np.int32(v)], True, (0,255,0), 3, cv2.LINE_AA)\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(train_rgb, k,\\\n",
    "                        (int((v[3,0,0] - v[0,0,0]) * 0.25 + v[0,0,0]),int((v[1,0,1] - v[0,0,1]) * 0.67 + v[0,0,1])),\\\n",
    "                        font, 5, (0,255,0), 10, cv2.LINE_AA)        \n",
    "            \n",
    "        \n",
    "    plt.imshow(train_rgb),plt.show();\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
