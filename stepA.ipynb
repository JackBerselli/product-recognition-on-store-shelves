{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_imgs = ['0','1','11','19','24','25','26']\n",
    "train_imgs = ['scenes/e1.png','scenes/e2.png','scenes/e3.png','scenes/e4.png','scenes/e5.png']\n",
    "true_imgs = {\n",
    "    'scenes/e1.png':{'0':1,'11':1},\n",
    "    'scenes/e2.png':{'24':1,'25':1,'26':1},\n",
    "    'scenes/e3.png':{'0':1,'1':1,'11':1},\n",
    "    'scenes/e4.png':{'0':1,'11':1,'25':1,'26':1},\n",
    "    'scenes/e5.png':{'19':1,'25':1},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_MATCH_COUNT = 88\n",
    "LOWE_COEFF = 0.7\n",
    "NUM_EPOCHS = 2\n",
    "COLOR_T = 50\n",
    "CONSISTENCY_COEFF = 0.5\n",
    "DIM_MIN = 0.5\n",
    "DIM_MAX = 2\n",
    "AREA_MIN = 0.5\n",
    "AREA_MAX = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scene: scenes/e5.png\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'cv2.DMatch' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-0be001bdcaf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mquery_color\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_bgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0msrc_pts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmatches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0mdst_pts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmatches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindHomography\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_pts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdst_pts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRANSAC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-0be001bdcaf6>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mquery_color\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_bgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0msrc_pts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmatches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0mdst_pts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmatches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindHomography\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_pts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdst_pts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRANSAC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'cv2.DMatch' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "for train_img in train_imgs:\n",
    "\n",
    "    train = cv2.imread(scene,0)\n",
    "    train_bgr = cv2.imread(scene)\n",
    "    train_rgb = cv2.cvtColor(train_bgr,cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    kp_train, des_train = sift.detectAndCompute(train,None)\n",
    "    \n",
    "    print(\"Scene: \"+scene+\"\\n\")\n",
    "    \n",
    "    global_matches = []\n",
    "    \n",
    "    for query_img in query_imgs:\n",
    "        \n",
    "        file = 'models/' + query_img + '.jpg'\n",
    "        query = cv2.imread(file,0)\n",
    "\n",
    "        kp_query, des_query = sift.detectAndCompute(query,None)\n",
    "\n",
    "        FLANN_INDEX_KDTREE = 1\n",
    "        index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "        search_params = dict(checks = 50)\n",
    "\n",
    "        flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "        matches = flann.knnMatch(des_query,des_train,k=2)\n",
    "\n",
    "        good_matches = []\n",
    "        for m,n in matches:\n",
    "            if m.distance < LOWE_COEFF * n.distance:\n",
    "                good_matches.append(m)\n",
    "                \n",
    "        global_matches.append((len(good_matches),query_img,good_matches))\n",
    "    \n",
    "    global_matches = sorted(global_matches,reverse=True)\n",
    "    \n",
    "    dimensions = []\n",
    "    areas = []\n",
    "    centers = []\n",
    "    \n",
    "    for matches in global_matches:\n",
    "\n",
    "        if matches[0] > MIN_MATCH_COUNT:\n",
    "            \n",
    "            file = 'models/' + matches[1] + '.jpg'\n",
    "            query_bgr = cv2.imread(file)\n",
    "            query_color = query_bgr.mean(axis=0).mean(axis=0)\n",
    "            \n",
    "            src_pts = np.float32([m[0].pt for m in matches[2]]).reshape(-1,1,2)\n",
    "            dst_pts = np.float32([m[1].pt for m in matches[2]]).reshape(-1,1,2)\n",
    "            M, mask = cv2.findHomography(src_pts,dst_pts,cv2.RANSAC,5.0)\n",
    "            h,w,d = query_bgr.shape\n",
    "            pts = np.float32([[0,0],[0,h-1],[w-1,h-1],[w-1,0]]).reshape(-1,1,2)\n",
    "            dst = cv2.perspectiveTransform(pts,M)\n",
    "            \n",
    "            x_minimum = int(np.min(dst,axis=0)[0][0])\n",
    "            y_minimum = int(np.min(dst,axis=0)[0][1])\n",
    "            x_maximum = int(np.max(dst,axis=0)[0][0])\n",
    "            y_maximum = int(np.max(dst,axis=0)[0][1])\n",
    "            \n",
    "            dimensions.append(((x_maximum-x_minimum),(y_maximum-y_minimum)))\n",
    "            delta.append(np.sqrt((x_minimum-x_maximum)**2+(y_minimum-y_maximum)**2))  \n",
    "            center = (int((x_maximum+x_minimum)/2),int((y_maximum+y_minimum)/2))\n",
    "            train_crop = train[y_minimum:y_maximum,x_minimum:x_maximum]\n",
    "            train_color = train_crop.mean(axis=0).mean(axis=0)\n",
    "            \n",
    "            color_diff = abs(query_color-train_color)\n",
    "            dist = []\n",
    "            area = 0\n",
    "            for i in range(3):\n",
    "                area += dst[i][0][0]*dst[i+1][0][1]-dst[i+1][0][0]*dst[i][0][1]\n",
    "            area += dst[3][0][0]*dst[0][0][1]-dst[0][0][0]*dst[3][0][1]\n",
    "            area = abs(area/2)\n",
    "            areas.append(area)\n",
    "            \n",
    "            for c in centers:\n",
    "                dist.append(np.sqrt((center[0]-c[0])**2+(center[1]-c[1])**2))\n",
    "            min_dist = float(\"inf\")\n",
    "            if len(dist)>0:\n",
    "                min_dist = min(dist)\n",
    "                \n",
    "            if max(color_diff)<COLOR_T and min_dist > delta[0]*CONSISTENCY_COEFF\\\n",
    "                and area/areas[0] > AREA_MIN and area/areas[0] < AREA_MAX\\\n",
    "                and (x_maximum-x_minimum)/dimensions[0][0] > DIM_MIN and (x_maximum-x_minimum)/dimensions[0][0] < DIM_MAX\\\n",
    "                and (y_maximum-y_minimum)/dimensions[0][1] > DIM_MIN and (y_maximum-y_minimum)/dimensions[0][1] < DIM_MAX\\\n",
    "                and dst[0][0][0] < dst[3][0][0]\\\n",
    "                and dst[1][0][0] < dst[2][0][0]\\\n",
    "                and dst[0][0][1] < dst[1][0][1]\\\n",
    "                and dst[3][0][1] < dst[2][0][1]:\n",
    "                train_rgb = cv2.polylines(train_rgb,[np.int32(dst)],True,(0,255,0),3, cv2.LINE_AA)\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                cv2.putText(train2, matches[0],\\\n",
    "                        (int((x_maximum-x_minimum)/4+x_minimum),int((y_maximum-y_minimum)*0.67+y_minimum)),\\\n",
    "                        font, 5, (0,127,255), 10, cv2.LINE_AA)\n",
    "                plt.imshow(train_rgb),plt.show();\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "#            src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "#            dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "#            M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "#            matchesMask = mask.ravel().tolist()\n",
    "#            h,w,d = img1.shape\n",
    "#            pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    "#            dst = cv2.perspectiveTransform(pts,M)\n",
    "#            draw_params = dict(matchColor = (0,0,0), # draw matches in green color\n",
    "#                           singlePointColor = None,\n",
    "#                           matchesMask = matchesMask, # draw only inliers\n",
    "#                           flags = 2)\n",
    "#            print( \"Product \" + img + \": enough matches are found!!! - {}/{}\".format(len(good), MIN_MATCH_COUNT) )\n",
    "#            img3 = cv2.drawMatches(img1,kp1,img2,kp2,good,None,**draw_params)\n",
    "#            plt.figure(figsize = (15,15))\n",
    "#            plt.imshow(img3),plt.show();\n",
    "#            if img in true_images[scene]:\n",
    "#                TP += 1\n",
    "#                TTP += 1\n",
    "#                img2 = cv2.polylines(img2,[np.int32(dst)],True,(0,255,0),3, cv2.LINE_AA)\n",
    "#                print(\"TP \" + img + \" (\" + str(len(good)) + \" matches)\")\n",
    "#            else:\n",
    "#                FP += 1\n",
    "#                TFP += 1\n",
    "#                img2 = cv2.polylines(img2,[np.int32(dst)],True,(255,0,0),3, cv2.LINE_AA)\n",
    "#                print(\"\\033[1m\" + \"FP \" + img + \" (\" + str(len(good)) + \" matches)\\033[0m\")\n",
    "#                problems.add(img)\n",
    "#        else:\n",
    "##            print( \"Product \" + img + \": not enough matches are found - {}/{}\".format(len(good), MIN_MATCH_COUNT) )\n",
    "#            matchesMask = None\n",
    "#            if img in true_images[scene]:\n",
    "#                FN += 1\n",
    "#                TFN += 1\n",
    "#                print(\"\\033[1m\" + \"FN \" + img + \" (\" + str(len(good)) + \" matches)\\033[0m\")\n",
    "#                problems.add(img)\n",
    "#            else:\n",
    "#                TN += 1\n",
    "#                TTN += 1\n",
    "#                print(\"TN \" + img + \" (\" + str(len(good)) + \" matches)\")\n",
    "#    print(\"\\n\" + \"TP: \" + str(TP) + \"\\t\" + \"FP: \" + str(FP) + \"\\t\" + \"TN: \" + str(TN) + \"\\t\" + \"FN: \" + str(FN) + \"\\n\")\n",
    "#    print(\"Accuracy: %.2f\" % ((TP+TN)/(TP+FP+TN+FN)*100) + \"%\\t\"+\"Precision: %.2f\" % (TP/(TP+FP)*100) + \"%\")\n",
    "#    print(\"Sensitivity: %.2f\" % (TP/(TP+FN)*100) + \"%\\t\"+\"Specificity: %.2f\" % (TN/(TN+FP)*100) + \"%\")\n",
    "#    print(\"F score: %.2f\" % (2*((TP/(TP+FP))*(TP/(TP+FN)))/((TP/(TP+FP))+(TP/(TP+FN)))))\n",
    "#    plt.imshow(img2),plt.show();\n",
    "#    print(\"\\n\")\n",
    "#print(\"\\n\\033[1m\" + \"TTP: \" + str(TTP) + \"\\t\" + \"TFP: \" + str(TFP) + \"\\t\" + \"TTN: \" + str(TTN) + \"\\t\" + \"TFN: \" + str(TFN) + \"\\033[0m\\n\")\n",
    "#print(\"\\033[1m\" + \"Total accuracy: %.2f\" % ((TTP+TTN)/(TTP+TFP+TTN+TFN)*100) + \"%\\t\\t\"+\"Total precision: %.2f\" % (TTP/(TTP+TFP)*100) + \"%\\033[0m\")\n",
    "#print(\"\\033[1m\" + \"Total sensitivity: %.2f\" % (TTP/(TTP+TFN)*100) + \"%\\t\"+\"Total specificity: %.2f\" % (TTN/(TTN+TFP)*100) + \"%\\033[0m\")\n",
    "#print(\"\\033[1m\" + \"Total F score: %.2f\" % (2*((TTP/(TTP+TFP))*(TTP/(TTP+TFN)))/((TTP/(TTP+TFP))+(TTP/(TTP+TFN)))) + \"\\033[0m\")\n",
    "\n",
    "#print(\"\\n\\n\" + \"Problematic images: \")\n",
    "#for img in problems:\n",
    "#    img1_bgr = cv2.imread(img)\n",
    "#    img1 = cv2.cvtColor(img1_bgr,cv2.COLOR_BGR2RGB)\n",
    "#    plt.imshow(img1),plt.show();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
