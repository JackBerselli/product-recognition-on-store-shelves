{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import skimage.morphology as sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sift = cv2.xfeatures2d.SIFT_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_B(query_imgs, train_img):\n",
    "    centers=[]\n",
    "    train = cv2.imread(train_img)\n",
    "    train4 = cv2.imread(train_img,0)\n",
    "    train5 = train4//2\n",
    "#    train3 = cv2.cvtColor(train,cv2.COLOR_BGR2RGB)\n",
    "#    train2 = np.zeros(train3.shape, train3.dtype)\n",
    "#    for y in range(train3.shape[0]):\n",
    "#        for x in range(train3.shape[1]):\n",
    "#            for c in range(train3.shape[2]):\n",
    "#                train2[y,x,c] = np.clip(0.5*train3[y,x,c],0, 255)\n",
    "##    train2 = cv2.cvtColor(train5,cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    kp_train, des_train = sift.detectAndCompute(train4,None)\n",
    "    fb =[]\n",
    "    global_matches_4d = {}\n",
    "    global_kp_query = {}\n",
    "    global_kp_train = {}\n",
    "    votes_total=[]\n",
    "    global_votes = {}\n",
    "    global_centers = {}\n",
    "    \n",
    "    for query_img in query_imgs:\n",
    "        \n",
    "        try:\n",
    "        \n",
    "            file = 'models/'+query_img+'.jpg'\n",
    "            query = cv2.imread(file,0)\n",
    "            kp_query, des_query = sift.detectAndCompute(query,None)\n",
    "\n",
    "\n",
    "            FLANN_INDEX_KDTREE = 1\n",
    "            index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "            search_params = dict(checks = 50)\n",
    "\n",
    "    #        flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "            flann = cv2.BFMatcher()\n",
    "\n",
    "\n",
    "            matches_preliminary = flann.knnMatch(des_train,des_query,k=2)\n",
    "\n",
    "            preliminary_kp_query = []\n",
    "            preliminary_kp_train = []\n",
    "\n",
    "            for m,n in matches_preliminary:\n",
    "                if m.distance < N_DIST_COEFF_PRELIM*n.distance:\n",
    "                    preliminary_kp_query.append(kp_query[m.trainIdx])\n",
    "                    preliminary_kp_train.append(kp_train[m.queryIdx])\n",
    "\n",
    "            ratio_scale_preliminary = []\n",
    "\n",
    "            for entry_query,entry_train in zip(preliminary_kp_query,preliminary_kp_train):\n",
    "\n",
    "                ratio_scale_preliminary.append(entry_train.size / entry_query.size)          \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            matches = flann.knnMatch(des_train,des_query,k=2)\n",
    "\n",
    "            good_kp_query = []\n",
    "            good_kp_train = []\n",
    "\n",
    "            if query.shape[0] >= 200:\n",
    "                N_DIST_COEFF = 0.9\n",
    "            if query.shape[0] >= 400:\n",
    "                N_DIST_COEFF = 0.8\n",
    "            if query.shape[0] >= 600:\n",
    "                N_DIST_COEFF = 0.7\n",
    "\n",
    "            for m,n in matches:\n",
    "                if m.distance < N_DIST_COEFF*n.distance:\n",
    "                    good_kp_query.append(kp_query[m.trainIdx])\n",
    "                    good_kp_train.append(kp_train[m.queryIdx])\n",
    "\n",
    "            global_kp_query[query_img] = good_kp_query\n",
    "            global_kp_train[query_img] = good_kp_train\n",
    "\n",
    "            query_xc = np.mean(list(good_kp_query[i].pt[0] for i in range(len(good_kp_query))))\n",
    "            query_yc = np.mean(list(good_kp_query[i].pt[1] for i in range(len(good_kp_query))))\n",
    "\n",
    "            matches_4d = []\n",
    "\n",
    "            for entry_query,entry_train in zip(good_kp_query,good_kp_train):\n",
    "\n",
    "                v = ((query_xc-entry_query.pt[0]), (query_yc-entry_query.pt[1]))\n",
    "                delta_angle = entry_train.angle - entry_query.angle\n",
    "                ratio_scale = entry_train.size / entry_query.size\n",
    "                train_xc = entry_train.pt[0] + ratio_scale * (np.cos(delta_angle) * v[0] - np.sin(delta_angle) * v[1])\n",
    "                train_yc = entry_train.pt[1] + ratio_scale * (np.sin(delta_angle) * v[0] + np.cos(delta_angle) * v[1])\n",
    "\n",
    "                matches_4d.append((train_xc,train_yc,delta_angle,ratio_scale))\n",
    "\n",
    "            global_matches_4d[query_img] = matches_4d  \n",
    "\n",
    "            ratio_scale_preliminary\n",
    "\n",
    "            counts_scale, bins_scale, patches_size = plt.hist(ratio_scale_preliminary,bins='auto')\n",
    "            img_scale = np.mean([bins_scale[np.argmax(counts_scale)],bins_scale[np.argmax(counts_scale)+1]])\n",
    "            plt.close();\n",
    "\n",
    "\n",
    "            data_scale = list(matches_4d[i][3] for i in range(len(matches_4d)))\n",
    "            counts_scale, bins_scale, patches_size = plt.hist(data_scale,bins='auto')\n",
    "            plt.close();\n",
    "\n",
    "            data_angle = list(matches_4d[i][2] for i in range(len(matches_4d)))\n",
    "            counts_angle, bins_angle, patches_angle = plt.hist(data_angle,bins='auto')\n",
    "            plt.close();\n",
    "\n",
    "            x_bin_size = img_scale * query.shape[1] * BIN_PRECISION_FACTOR\n",
    "            y_bin_size = img_scale * query.shape[0] * BIN_PRECISION_FACTOR\n",
    "            x_bins = int(np.ceil(train.shape[1]/x_bin_size)+2)\n",
    "            y_bins = int(np.ceil(train.shape[0]/y_bin_size)+2)\n",
    "            x_min = train.shape[1]/2 - x_bins/2 * x_bin_size\n",
    "            y_min = train.shape[0]/2 - y_bins/2 * y_bin_size\n",
    "            x_max = train.shape[1]/2 + x_bins/2 * x_bin_size\n",
    "            y_max = train.shape[0]/2 + y_bins/2 * y_bin_size\n",
    "\n",
    "\n",
    "\n",
    "    #        print(\"Query: {}\".format(query_img))\n",
    "    #        fig = plt.figure(figsize = (8,8))\n",
    "    #        plt.rc('grid', linestyle=\"-\", color='red')\n",
    "    #        ax = fig.gca()\n",
    "    #        ax.set_xticks(np.arange(x_min, x_max, x_bin_size))\n",
    "    #        ax.set_yticks(np.arange(y_min, y_max, y_bin_size))\n",
    "    #        plt.grid()\n",
    "    #        plt.imshow(train2),plt.show();\n",
    "\n",
    "\n",
    "\n",
    "            angle_bin_size = np.std(data_angle)*ANGLE_BIN_SIZE_COEFF\n",
    "            angle_bin_center = np.mean(data_angle)\n",
    "            angle_min = angle_bin_center - ANGLE_BINS/2 * angle_bin_size\n",
    "            angle_max = angle_bin_center + ANGLE_BINS/2 * angle_bin_size\n",
    "\n",
    "            #SCALE_BINS = 7\n",
    "            scale_bin_size = np.std(data_scale)*SCALE_BIN_SIZE_COEFF\n",
    "            scale_bin_center = np.mean(data_scale)\n",
    "            scale_min = 0 #scale_bin_center - SCALE_BINS/2 * scale_bin_size\n",
    "            scale_max = scale_bin_center * 2 #scale_bin_center + SCALE_BINS/2 * scale_bin_size\n",
    "            SCALE_BINS = int((scale_max-scale_min)/scale_bin_size)\n",
    "\n",
    "            def votesOnMatch(m_4d):\n",
    "\n",
    "                accumulator = np.zeros((x_bins,y_bins,ANGLE_BINS,SCALE_BINS))\n",
    "                votes = {}\n",
    "\n",
    "                for m in m_4d:\n",
    "                    try:\n",
    "                        for x in range(0,2):\n",
    "                            for y in range(0,2):\n",
    "                                for z in range(0,2):\n",
    "                                    for w in range(0,2):                \n",
    "                                        i = int(np.floor((m[0]-x_min+(x-1/2)*x_bin_size)/x_bin_size))\n",
    "                                        j = int(np.floor((m[1]-y_min+(y-1/2)*y_bin_size)/y_bin_size))\n",
    "                                        k = int(np.floor((m[2]-angle_min+(z-1/2)*angle_bin_size)/angle_bin_size))\n",
    "                                        l = int(np.floor((m[3]-scale_min+(w-1/2)*scale_bin_size)/scale_bin_size))\n",
    "                                        if i >= 0 and j >= 0 and k >= 0 and l >= 0:\n",
    "                                            accumulator[i][j][k][l]+=1\n",
    "                                            votes[(i,j,k,l)] = votes.get((i,j,k,l),[])\n",
    "                                            votes[(i,j,k,l)].append(m)\n",
    "                    except: pass\n",
    "\n",
    "                return accumulator,votes\n",
    "\n",
    "            accumulator,votes=votesOnMatch(matches_4d)\n",
    "\n",
    "            T = T_Q+int(query.shape[0]*T_M)\n",
    "\n",
    "    #        a = accumulator\n",
    "    #        for epoch in range(NUM_EPOCHS):\n",
    "    #            a1 = np.zeros((x_bins,y_bins,ANGLE_BINS,SCALE_BINS))\n",
    "    #            for i in range(x_bins):\n",
    "    #                for j in range(y_bins):\n",
    "    #                    for k in range(ANGLE_BINS):\n",
    "    #                        for l in range(SCALE_BINS):\n",
    "    #                            counter = 0\n",
    "    #                            for x in range(-NEIGH,NEIGH+1):\n",
    "    #                                for y in range(-NEIGH,NEIGH+1):\n",
    "    #                                    for z in range(-NEIGH,NEIGH+1):\n",
    "    #                                        for w in range(-NEIGH,NEIGH+1):\n",
    "    #                                            try:\n",
    "    #                                                counter += a[i+x][j+y][k+z][l+w]\n",
    "    #                                                if a1[i][j][k][l] == 0 and a[i][j][k][l] < a[i+x][j+y][k+z][l+w]:\n",
    "    #                                                    a1[i][j][k][l] = -1\n",
    "    #                                            except: pass\n",
    "    #                            if a1[i][j][k][l] == 0 and a[i][j][k][l] >= T:\n",
    "    #                                a1[i][j][k][l] = counter\n",
    "    #                            else:\n",
    "    #                                a1[i][j][k][l] = 0\n",
    "    #            a = a1\n",
    "    #            \n",
    "    #        threshold = THRESHOLD_Q+int(query.shape[0]*THRESHOLD_M)\n",
    "    #        \n",
    "    #        global_votes[query_img] = votes\n",
    "    #        \n",
    "    #        votes_total += [a1[tuple(b)]/threshold for b in list(np.argwhere(a1>=threshold))]\n",
    "    #        \n",
    "    #        fb+=[(query_img,tuple(b)) for b in list(np.argwhere(a1>=threshold))]\n",
    "\n",
    "            a2 = accumulator\n",
    "            mask=sk.local_maxima(a2)\n",
    "            a2[mask!=1] = 0\n",
    "    #        print(sorted(np.ravel(a2))[-5:])\n",
    "\n",
    "            global_votes[query_img] = votes\n",
    "            global_centers[query_img] = (query_xc,query_yc)\n",
    "\n",
    "            votes_total += [a2[tuple(b)] for b in list(np.argwhere(a2>=T))]\n",
    "\n",
    "            fb+=[(query_img,tuple(b)) for b in list(np.argwhere(a2>=T))]\n",
    "\n",
    "    #        print(query_img,str(int(np.max(accumulator)))+'/'+str(T),'->',str(int(np.max(a1)))+'/'+str(threshold))\n",
    "        except:\n",
    "            pass\n",
    "#    print(fb,votes_total)\n",
    "    \n",
    "    found_bins = [x for _,x in sorted(zip(votes_total,fb))[::-1]]\n",
    "    better_matches = []\n",
    "    better_centers = []\n",
    "#    print(found_bins)\n",
    "    \n",
    "    for b in found_bins:\n",
    "        matches = []\n",
    "        ccc = []\n",
    "        for i in range(len(global_matches_4d[b[0]])):\n",
    "            if global_matches_4d[b[0]][i] in global_votes[b[0]][tuple(b[1])]:\n",
    "                matches.append((global_kp_query[b[0]][i],global_kp_train[b[0]][i]))\n",
    "                ccc.append((global_matches_4d[b[0]][i][0],global_matches_4d[b[0]][i][1]))\n",
    "        better_matches.append((b[0],matches))\n",
    "        better_centers.append(ccc)\n",
    "\n",
    "    delta = []\n",
    "    areas = []\n",
    "    dimensions = []\n",
    "    for j in range(len(better_matches)):\n",
    "        try:\n",
    "            train2 = cv2.cvtColor(train5,cv2.COLOR_GRAY2RGB)\n",
    "            matches = better_matches[j]\n",
    "            better_c = better_centers[j]\n",
    "            file = 'models/'+matches[0]+'.jpg'\n",
    "            query = cv2.imread(file,0)\n",
    "            query2 = cv2.imread(file)\n",
    "            query_color = query2.mean(axis=0).mean(axis=0)\n",
    "            src_pts = np.float32([ m[0].pt for m in matches[1] ]).reshape(-1,1,2)\n",
    "            dst_pts = np.float32([ m[1].pt for m in matches[1] ]).reshape(-1,1,2)\n",
    "            M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "            matchesMask = mask.ravel().tolist()\n",
    "            h,w = query.shape\n",
    "            pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    "            dst = cv2.perspectiveTransform(pts,M)\n",
    "#            print(np.float32(list(global_centers[matches[0]])).reshape(-1,1,2))\n",
    "            new_center = cv2.perspectiveTransform(np.float32(list(global_centers[matches[0]])).reshape(-1,1,2),M)[0][0]\n",
    "            x_minimum = int(max(np.min(dst,axis=0)[0][0],0))\n",
    "            y_minimum = int(max(np.min(dst,axis=0)[0][1],0))\n",
    "            x_maximum = int(min(np.max(dst,axis=0)[0][0],train.shape[1]))\n",
    "            y_maximum = int(min(np.max(dst,axis=0)[0][1],train.shape[0]))\n",
    "\n",
    "            \n",
    "            for ijk in range(NUM_EPOCHS):\n",
    "            \n",
    "                dst_pts2 = []\n",
    "                src_pts2 = []\n",
    "\n",
    "    #            print(dst_pts)\n",
    "\n",
    "                for i in range(len(src_pts)):\n",
    "                    if dst_pts[i][0][0] > x_minimum and dst_pts[i][0][0] < x_maximum\\\n",
    "                    and dst_pts[i][0][1] > y_minimum and dst_pts[i][0][1] < y_maximum:\n",
    "                        dst_pts2.append([dst_pts[i][0][0],dst_pts[i][0][1]])\n",
    "                        src_pts2.append([src_pts[i][0][0],src_pts[i][0][1]])\n",
    "\n",
    "    #            print(dst_pts2)\n",
    "\n",
    "                src_pts = np.float32(src_pts2).reshape(-1,1,2)\n",
    "                dst_pts = np.float32(dst_pts2).reshape(-1,1,2)\n",
    "            \n",
    "            for pt in dst_pts:\n",
    "                cv2.circle(train2, (int(pt[0][0]),int(pt[0][1])), radius=3, color=(0, 191, 0), thickness=5)\n",
    "            M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "            matchesMask = mask.ravel().tolist()\n",
    "            h,w = query.shape\n",
    "            pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    "            dst = cv2.perspectiveTransform(pts,M)\n",
    "#            print(np.float32(list(global_centers[matches[0]])).reshape(-1,1,2))\n",
    "            new_center = cv2.perspectiveTransform(np.float32(list(global_centers[matches[0]])).reshape(-1,1,2),M)[0][0]\n",
    "            x_minimum = int(max(np.min(dst,axis=0)[0][0],0))\n",
    "            y_minimum = int(max(np.min(dst,axis=0)[0][1],0))\n",
    "            x_maximum = int(min(np.max(dst,axis=0)[0][0],train.shape[1]))\n",
    "            y_maximum = int(min(np.max(dst,axis=0)[0][1],train.shape[0]))\n",
    "            \n",
    "            dimensions.append(((x_maximum-x_minimum),(y_maximum-y_minimum)))\n",
    "            delta.append(np.sqrt((x_minimum-x_maximum)**2+(y_minimum-y_maximum)**2))\n",
    "            center = (int((x_maximum+x_minimum)/2),int((y_maximum+y_minimum)/2))\n",
    "            train_crop = train[y_minimum:y_maximum,x_minimum:x_maximum]\n",
    "            train_color = train_crop.mean(axis=0).mean(axis=0)\n",
    "            draw_params = dict(matchColor = (0,0,0), # draw matches in green color\n",
    "                           singlePointColor = None,\n",
    "                           matchesMask = matchesMask, # draw only inliers\n",
    "                           flags = 2)\n",
    "            color_diff = abs(query_color-train_color)\n",
    "            dist = []\n",
    "            area = 0\n",
    "            for i in range(3):\n",
    "                area += dst[i][0][0]*dst[i+1][0][1]-dst[i+1][0][0]*dst[i][0][1]\n",
    "            area += dst[3][0][0]*dst[0][0][1]-dst[0][0][0]*dst[3][0][1]\n",
    "            area = abs(area/2)\n",
    "            areas.append(area)\n",
    "            for c in centers:\n",
    "                dist.append(np.sqrt((center[0]-c[0])**2+(center[1]-c[1])**2))\n",
    "            min_dist = float(\"inf\")\n",
    "            if len(dist)>0:\n",
    "                min_dist = min(dist)\n",
    "#                print(min_dist)\n",
    "            if max(color_diff)<COLOR_T and min_dist > delta[0]*CONSISTENCY_COEFF\\\n",
    "                and area/areas[0] > AREA_MIN and area/areas[0] < AREA_MAX\\\n",
    "                and (x_maximum-x_minimum)/dimensions[0][0] > DIM_MIN and (x_maximum-x_minimum)/dimensions[0][0] < DIM_MAX\\\n",
    "                and (y_maximum-y_minimum)/dimensions[0][1] > DIM_MIN and (y_maximum-y_minimum)/dimensions[0][1] < DIM_MAX\\\n",
    "                and dst[0][0][0] < dst[3][0][0]\\\n",
    "                and dst[1][0][0] < dst[2][0][0]\\\n",
    "                and dst[0][0][1] < dst[1][0][1]\\\n",
    "                and dst[3][0][1] < dst[2][0][1]:\n",
    "                train2 = cv2.polylines(train2,[np.int32(dst)],True,(0,255,0),3, cv2.LINE_AA)\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                cv2.putText(train2, matches[0],\\\n",
    "                        (int((x_maximum-x_minimum)/4+x_minimum),int((y_maximum-y_minimum)*0.67+y_minimum)),\\\n",
    "                        font, 5, (0,127,255), 10, cv2.LINE_AA)\n",
    "                x_accu=[]\n",
    "                y_accu=[]\n",
    "                for b_c in better_c:\n",
    "                    cv2.circle(train2, (int(b_c[0]),int(b_c[1])), radius=3, color=(127, 0, 127), thickness=5)\n",
    "                    x_accu.append(b_c[0])\n",
    "                    y_accu.append(b_c[1])\n",
    "                cv2.circle(train2, (int(np.mean(x_accu)),int(np.mean(y_accu))), radius=5, color=(255, 0, 255), thickness=15)\n",
    "                cv2.circle(train2, (int(new_center[0]),int(new_center[1])), radius=5, color=(255, 191, 0), thickness=10)\n",
    "#                print(matches[0])\n",
    "                centers.append(center)\n",
    "                plt.imshow(train2),plt.show();\n",
    "        except: pass\n",
    "#    plt.figure(figsize = (15,10))\n",
    "##    plt.imshow(train2),plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "N_DIST_COEFF_PRELIM = 0.7\n",
    "DIM_MIN = 0.5\n",
    "DIM_MAX = 2\n",
    "AREA_MIN = 0.5\n",
    "AREA_MAX = 2\n",
    "N_DIST_COEFF = 0.9\n",
    "BIN_PRECISION_FACTOR = 0.25 #ottimizzato 0.25\n",
    "ANGLE_BINS = 7\n",
    "ANGLE_BIN_SIZE_COEFF = 0.1\n",
    "SCALE_BIN_SIZE_COEFF = 0.1\n",
    "NEIGH = 1\n",
    "NUM_EPOCHS = 2\n",
    "T_Q = 5 #5\n",
    "T_M = 0 #1/25\n",
    "THRESHOLD_Q = 200 #ottimizzato 200\n",
    "THRESHOLD_M = 1/3\n",
    "COLOR_T = 50\n",
    "CONSISTENCY_COEFF = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "query_imgs = ['0','1','11','19','24','25','26']\n",
    "#query_imgs = ['0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','26']\n",
    "train_imgs = ['scenes/e1.png','scenes/e2.png','scenes/e3.png','scenes/e4.png','scenes/e5.png','scenes/m1.png','scenes/m2.png','scenes/m3.png','scenes/m4.png','scenes/m5.png']\n",
    "for train_img in train_imgs:\n",
    "    step_B(query_imgs, train_img)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "#query_imgs = ['0','1','11','19','24','25','26']\n",
    "query_imgs = ['0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','26']\n",
    "#train_imgs = ['scenes/e1.png','scenes/e2.png','scenes/e3.png','scenes/e4.png','scenes/e5.png','scenes/m1.png','scenes/m2.png','scenes/m3.png','scenes/m4.png','scenes/m5.png']\n",
    "train_imgs = ['scenes/h1.jpg']#,'scenes/h2.jpg','scenes/h3.jpg','scenes/h4.jpg','scenes/h5.jpg']\n",
    "for N_DIST_COEFF in [0.9,0.95,0.99]:\n",
    "    for BIN_PRECISION_FACTOR in [0.1,0.15,0.2]:\n",
    "        for T_Q in [3]:#,5,7]:\n",
    "            for CONSISTENCY_COEFF in [0.25,0.33,0.5]:\n",
    "                print(N_DIST_COEFF,BIN_PRECISION_FACTOR,T_Q,CONSISTENCY_COEFF)\n",
    "                for train_img in train_imgs:\n",
    "                    print(train_img)\n",
    "                    step_B(query_imgs, train_img)\n",
    "                print(\"\\n\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# PARAMETERS\n",
    "N_DIST_COEFF_PRELIM = 0.7\n",
    "DIM_MIN = 0.5\n",
    "DIM_MAX = 2\n",
    "AREA_MIN = 0.5\n",
    "AREA_MAX = 2\n",
    "N_DIST_COEFF = 0.95\n",
    "BIN_PRECISION_FACTOR = 0.33 #ottimizzato 0.25\n",
    "ANGLE_BINS = 7\n",
    "ANGLE_BIN_SIZE_COEFF = 0.1\n",
    "SCALE_BIN_SIZE_COEFF = 0.1\n",
    "NEIGH = 1\n",
    "NUM_EPOCHS = 2\n",
    "T_Q = 3 #5\n",
    "T_M = 0 #1/25\n",
    "THRESHOLD_Q = 200 #ottimizzato 200\n",
    "THRESHOLD_M = 1/3\n",
    "COLOR_T = 50\n",
    "CONSISTENCY_COEFF = 0.33"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "query_imgs = ['0','1','11','19','24','25','26']\n",
    "#query_imgs = ['0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','26']\n",
    "train_imgs = ['scenes/h1.jpg']\n",
    "for train_img in train_imgs:\n",
    "    step_B(query_imgs, train_img)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#STEP B\n",
    "query_imgs = ['0','1','11','19','24','25','26']\n",
    "#query_imgs = ['0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','26']\n",
    "train_imgs = ['scenes/m1.png','scenes/m2.png','scenes/m3.png','scenes/m4.png','scenes/m5.png']\n",
    "for train_img in train_imgs:\n",
    "    step_B(query_imgs, train_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
