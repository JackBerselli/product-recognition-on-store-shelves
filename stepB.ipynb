{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd \n",
    "import skimage.morphology as sk\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "N_DIST_COEFF_PRELIM = 0.7\n",
    "DIM_MIN = 0.5\n",
    "DIM_MAX = 2\n",
    "AREA_MIN = 0.5\n",
    "AREA_MAX = 2\n",
    "N_DIST_COEFF = 0.9\n",
    "BIN_PRECISION_FACTOR = 0.25 #ottimizzato 0.25\n",
    "ANGLE_BINS = 7\n",
    "ANGLE_BIN_SIZE_COEFF = 0.1\n",
    "SCALE_BIN_SIZE_COEFF = 0.1\n",
    "NEIGH = 1\n",
    "NUM_EPOCHS = 2\n",
    "T_Q = 5 #5\n",
    "T_M = 0 #1/25\n",
    "THRESHOLD_Q = 200 #ottimizzato 200\n",
    "THRESHOLD_M = 1/3\n",
    "COLOR_T = 50\n",
    "CONSISTENCY_COEFF = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_all_keypoints():\n",
    "\n",
    "    image_dict = {}\n",
    "\n",
    "    for img in query_imgs:\n",
    "        file = 'models/'+img+'.jpg'\n",
    "        query = cv2.imread(file,0)\n",
    "        kp, des = sift.detectAndCompute(query,None)\n",
    "        image_dict[img] = {'kp': kp,'des': des,'shape': query.shape}\n",
    "\n",
    "    for img in train_imgs:\n",
    "        file = 'scenes/'+img+'.png'\n",
    "        train = cv2.imread(file,0)\n",
    "        kp, des = sift.detectAndCompute(train,None)\n",
    "        image_dict[img] = {'kp': kp,'des': des, 'shape': query.shape}\n",
    "\n",
    "    return image_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_ratio_test(all_matches,coeff):\n",
    "\n",
    "    good_matches = {}      #map of matches kp_train_idx -> kp_query_idx\n",
    "    \n",
    "    for m,n in all_matches:\n",
    "        if m.distance < coeff*n.distance:\n",
    "            good_matches[m.queryIdx]= m.trainIdx\n",
    "\n",
    "    return good_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_entry_hough_space(kp_q,kp_t,q_xc,q_yc):\n",
    "\n",
    "    entry = {}\n",
    "\n",
    "    v = ((q_xc-kp_q.pt[0]), (q_yc-kp_q.pt[1]))\n",
    "    scale_ratio = kp_t.size/kp_q.size\n",
    "    delta_angle = kp_t.angle-kp_q.angle\n",
    "    x_c = kp_t.pt[0] + scale_ratio * (np.cos(delta_angle) * v[0] - np.sin(delta_angle) * v[1])\n",
    "    y_c = kp_t.pt[1] + scale_ratio * (np.sin(delta_angle) * v[0] + np.cos(delta_angle) * v[1])\n",
    "\n",
    "    entry['x_c']= x_c\n",
    "    entry['y_c']= y_c\n",
    "    entry['scale_ratio'] = scale_ratio\n",
    "    entry['delta_angle'] = delta_angle\n",
    "   \n",
    "\n",
    "    return entry "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hough_space(good_matches,kp_query,kp_train,query_xc,query_yc):\n",
    "    \n",
    "    hough_space = {}     #map of hough space kp_train_idx -> map name-values\n",
    "\n",
    "    for t_idx,q_idx in good_matches.items():\n",
    "        hough_space[t_idx] = compute_entry_hough_space(kp_query[q_idx],kp_train[t_idx],query_xc,query_yc)\n",
    "    \n",
    "    return hough_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bins(hough_space,query_shape,train_shape):\n",
    "\n",
    "    values = {}\n",
    "    \n",
    "    data_scale = [entry['scale_ratio'] for entry in hough_space.values()]\n",
    "    counts_scale, bins_scale, patches_size = plt.hist(data_scale,bins='auto')\n",
    "    img_scale = np.mean([bins_scale[np.argmax(counts_scale)],bins_scale[np.argmax(counts_scale)+1]])\n",
    "    plt.close();\n",
    "\n",
    "    data_angle = [entry['delta_angle'] for entry in hough_space.values()]\n",
    "    counts_angle, bins_angle, patches_angle = plt.hist(data_angle,bins='auto')\n",
    "    plt.close();\n",
    "\n",
    "    x_bin_size = img_scale * query_shape[1] * BIN_PRECISION_FACTOR\n",
    "    y_bin_size = img_scale * query_shape[0] * BIN_PRECISION_FACTOR\n",
    "    x_bins = int(np.ceil(train_shape[1]/x_bin_size)+2)\n",
    "    y_bins = int(np.ceil(train_shape[0]/y_bin_size)+2)\n",
    "    x_min = train_shape[1]/2 - x_bins/2 * x_bin_size\n",
    "    y_min = train_shape[0]/2 - y_bins/2 * y_bin_size\n",
    "\n",
    "    angle_bin_size = np.std(data_angle)*ANGLE_BIN_SIZE_COEFF\n",
    "    angle_bin_center = np.mean(data_angle)\n",
    "    angle_min = angle_bin_center - ANGLE_BINS/2 * angle_bin_size\n",
    "    angle_max = angle_bin_center + ANGLE_BINS/2 * angle_bin_size\n",
    "\n",
    "    scale_bin_size = np.std(data_scale)*SCALE_BIN_SIZE_COEFF\n",
    "    scale_bin_center = np.mean(data_scale)\n",
    "    scale_min = 0 \n",
    "    scale_max = scale_bin_center * 2 \n",
    "    scale_bins = int((scale_max-scale_min)/scale_bin_size)\n",
    "\n",
    "    values['x_bins'] = x_bins\n",
    "    values['y_bins'] = y_bins\n",
    "    values['x_min'] = x_min\n",
    "    values['y_min'] = y_min\n",
    "    values['x_bin_size'] = x_bin_size\n",
    "    values['y_bin_size'] = y_bin_size\n",
    "    values['scale_bins'] = scale_bins\n",
    "    values['scale_min'] = scale_min\n",
    "    values['scale_bin_size'] = scale_bin_size\n",
    "    values['angle_min'] = angle_min\n",
    "    values['angle_min_size'] = angle_bin_size \n",
    "\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voting(b,h_s):\n",
    "\n",
    "    accumulator = np.zeros((b['x_bins'],b['y_bins'],ANGLE_BINS,b['scale_bins']))\n",
    "\n",
    "    votes = {}\n",
    "\n",
    "    for k,v in h_s.items():\n",
    "        try:\n",
    "            for x in range(0,2):\n",
    "                for y in range(0,2):\n",
    "                    for z in range(0,2):\n",
    "                        for w in range(0,2):                \n",
    "                            i = int(np.floor((v['x_c']-b['x_min']+(x-1/2)*b['x_bin_size'])/b['x_bin_size']))\n",
    "                            j = int(np.floor((v['y_c']-b['y_min']+(y-1/2)*b['y_bin_size'])/b['y_bin_size']))\n",
    "                            k = int(np.floor((v['delta_angle']-b['angle_min']+(z-1/2)*b['angle_bin_size'])/b['angle_bin_size']))\n",
    "                            l = int(np.floor((v['scale_ratio']-b['scale_min']+(w-1/2)*b['scale_bin_size'])/b['scale_bin_size']))\n",
    "                            if i >= 0 and j >= 0 and k >= 0 and l >= 0:\n",
    "                                accumulator[i][j][k][l]+=1\n",
    "                                votes[(i,j,k,l)] = votes.get((i,j,k,l),[])\n",
    "                                votes[(i,j,k,l)].append(k)\n",
    "        except: pass\n",
    "\n",
    "    return accumulator,votes\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_imgs = ['0','1','11','19','24','25','26']\n",
    "train_imgs = ['e1','e2','e3','e4','e5','m1','m2','m3','m4','m5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_B(query_imgs, train_img, image_dict):\n",
    "\n",
    "    global_correspondences = []\n",
    "    recognised = {}\n",
    "\n",
    "    for query_img in query_imgs:\n",
    "\n",
    "        kp_query, des_query = image_dict[query_img]['kp'], image_dict[query_img]['des']\n",
    "        kp_train, des_train = image_dict[train_img]['kp'], image_dict[train_img]['des']\n",
    "\n",
    "        all_matches = bf.knnMatch(des_train, des_query, k=2)\n",
    "\n",
    "        if image_dict[query_img]['shape'][0] >= 200:\n",
    "            N_DIST_COEFF = 0.9\n",
    "        if image_dict[query_img]['shape'][0] >= 400:\n",
    "            N_DIST_COEFF = 0.8\n",
    "        if image_dict[query_img]['shape'][0] >= 600:\n",
    "            N_DIST_COEFF = 0.7\n",
    "\n",
    "        #map of matching keypoint indexes\n",
    "        good_matches = apply_ratio_test(all_matches, N_DIST_COEFF)\n",
    "\n",
    "        #barycenter of found query keypoint \n",
    "        query_xc = np.mean(list(kp_query[i].pt[0] for i in range(len(kp_query))))\n",
    "        query_yc = np.mean(list(kp_query[i].pt[1] for i in range(len(kp_query))))\n",
    "\n",
    "        #create hough space \n",
    "        hough_space = create_hough_space(good_matches,kp_query,kp_train,query_xc,query_yc)\n",
    "\n",
    "        #compute all the values related to the size \n",
    "        bins_values = compute_bins(hough_space,image_dict[query_img]['shape'],image_dict[train_img]['shape'])\n",
    "\n",
    "        #create and populate accumulator with voting by each entry of the hough space \n",
    "        accumulator,votes= voting(bins_values,hough_space)\n",
    "\n",
    "        #compute local maxima of the 4d accumulator \n",
    "        mask=sk.local_maxima(accumulator)\n",
    "        accumulator[mask!=1] = 0\n",
    "\n",
    "        #store in a list all the correspondeces between query points and train points that voted for a local maxima \n",
    "            #the list contain: number of votes that a local maxima bin has received, name of query                                                                                                   image, list of query and train keypoints which voted for that bin \n",
    "\n",
    "        T = T_Q+int(image_dict[query_img]['shape'][0]*T_M)               #threhsold to come up with few maxima \n",
    "\n",
    "        for b in list(np.argwhere(accumulator>=T)):\n",
    "            keypoint_index_list = votes[tuple(b)]       #all query keypoint who voted for a local maxima bin \n",
    "            correspondence_list = [(kp_train[k],kp_query[good_matches[k]]) for k in keypoint_index_list]\n",
    "            global_correspondences.append([accumulator[tuple(b)],query_img,correspondece_list])\n",
    "\n",
    "    g_c = sorted(global_correspondences, key=itemgetter(0), reverse=True )    #sorted correspondences based on number of votes found in local maxima bins \n",
    "\n",
    "    #qui ci va un commento \n",
    "    for entry in g_c:\n",
    "        try:\n",
    "\n",
    "            query_file = 'models/'+entry[1]+'.jpg'\n",
    "            query_bgr = cv2.imread(query_file)\n",
    "            \n",
    "            src_pts = np.float32([e[1].pt for e in entry[2]]).reshape(-1, 1, 2)\n",
    "            dst_pts = np.float32([e[0].pt for e in entry[2]]).reshape(-1, 1, 2)\n",
    "            M, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "            h, w, d = query_bgr.shape\n",
    "            pts = np.float32([[0,0],[0,h-1],[w-1,h-1],[w-1,0]]).reshape(-1,1,2)\n",
    "            dst = cv2.perspectiveTransform(pts, M)\n",
    "        \n",
    "            center = tuple((dst[0,0,i] + dst[1,0,i] + dst[2,0,i] + dst[3,0,i]) / 4 for i in (0,1))\n",
    "                                  \n",
    "            x_min = int(max((dst[0,0,0] + dst[1,0,0]) / 2, 0))\n",
    "            y_min = int(max((dst[0,0,1] + dst[3,0,1]) / 2, 0))\n",
    "            x_max = int(min((dst[2,0,0] + dst[3,0,0]) / 2, train.shape[1]))\n",
    "            y_max = int(min((dst[1,0,1] + dst[2,0,1]) / 2, train.shape[0]))\n",
    "\n",
    "            query_color = query_bgr.mean(axis=0).mean(axis=0)\n",
    "            train_crop = train_bgr[y_min:y_max,x_min:x_max]\n",
    "            train_color = train_crop.mean(axis=0).mean(axis=0)   \n",
    "            color_diff = np.sqrt(np.sum([value ** 2 for value in abs(query_color - train_color)]))\n",
    "            \n",
    "\n",
    "            temp = True \n",
    "            if color_diff < COLOR_T :\n",
    "                for k, v in recognised.items():\n",
    "                    for corners in v:\n",
    "                        if center[0] > corners[0,0,0] and center[0] < corners[3,0,0]\\\n",
    "                            and center[1] > corners[0,0,1] and center[1] < corners[1,0,1]:\n",
    "                            temp = False\n",
    "                            break\n",
    "                if temp:\n",
    "                    recognised[entry[1]] = recognised.get(entry[1],[])  \n",
    "                    recognised[entry[1]].append(dst)\n",
    "        except: pass\n",
    "\n",
    "    train_file = 'scenes/' + train_img\n",
    "    train = cv2.imread(train_file, 0)              \n",
    "    train_rgb = cv2.cvtColor(train, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    for k, v in recognised.items():\n",
    "        for dst in v:\n",
    "            \n",
    "            train_rgb = cv2.polylines(train_rgb, [np.int32(dst)], True, (0,255,0), 3, cv2.LINE_AA)\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            cv2.putText(train_rgb, k,\\\n",
    "                            (int((v[3,0,0] - v[0,0,0]) * 0.25 + v[0,0,0]),int((v[1,0,1] - v[0,0,1]) * 0.67 + v[0,0,1])),\\\n",
    "                            font, 5, (0,255,0), 10, cv2.LINE_AA)        \n",
    "            \n",
    "        \n",
    "    plt.imshow(train_rgb),plt.show();\n",
    "    print('\\n')\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "Image data cannot be converted to float",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-fa3c40d6c353>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtrain_img\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_imgs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mstep_B\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery_imgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_img\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimage_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-01d96afad95f>\u001b[0m in \u001b[0;36mstep_B\u001b[1;34m(query_imgs, train_img, image_dict)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_rgb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\CV_Uni\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, data, **kwargs)\u001b[0m\n\u001b[0;32m   2651\u001b[0m         \u001b[0mvmax\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvmax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morigin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morigin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2652\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimlim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2653\u001b[1;33m         resample=resample, url=url, data=data, **kwargs)\n\u001b[0m\u001b[0;32m   2654\u001b[0m     \u001b[0msci\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2655\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\CV_Uni\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1783\u001b[0m                         \u001b[1;34m\"the Matplotlib list!)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1784\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[1;32m-> 1785\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1787\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[1;32m~\\miniconda3\\envs\\CV_Uni\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[0;32m   5470\u001b[0m                               resample=resample, **kwargs)\n\u001b[0;32m   5471\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5472\u001b[1;33m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5473\u001b[0m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5474\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\CV_Uni\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mset_data\u001b[1;34m(self, A)\u001b[0m\n\u001b[0;32m    640\u001b[0m         if (self._A.dtype != np.uint8 and\n\u001b[0;32m    641\u001b[0m                 not np.can_cast(self._A.dtype, float, \"same_kind\")):\n\u001b[1;32m--> 642\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Image data cannot be converted to float\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    643\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m         if not (self._A.ndim == 2\n",
      "\u001b[1;31mTypeError\u001b[0m: Image data cannot be converted to float"
     ]
    }
   ],
   "source": [
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "bf = cv2.BFMatcher()\n",
    "\n",
    "image_dict = compute_all_keypoints()\n",
    "\n",
    "for train_img in train_imgs:\n",
    "\n",
    "    step_B(query_imgs, train_img,image_dict)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def step_B(query_imgs, train_img):\n",
    "#     centers=[]\n",
    "#     train = cv2.imread(train_img)\n",
    "#     train4 = cv2.imread(train_img,0)\n",
    "#     train5 = train4//2\n",
    "\n",
    "    \n",
    "#     kp_train, des_train = sift.detectAndCompute(train4,None)\n",
    "#     fb =[]\n",
    "#     global_matches_4d = {}\n",
    "#     global_kp_query = {}\n",
    "#     global_kp_train = {}\n",
    "#     votes_total=[]\n",
    "#     global_votes = {}\n",
    "#     global_centers = {}\n",
    "    \n",
    "#     for query_img in query_imgs:\n",
    "        \n",
    "#         try:\n",
    "        \n",
    "\n",
    "#             kp_query, des_query = sift.detectAndCompute(query,None)\n",
    "\n",
    "#             flann = cv2.BFMatcher()\n",
    "\n",
    "\n",
    "#             matches_preliminary = flann.knnMatch(des_train,des_query,k=2)\n",
    "\n",
    "#             preliminary_kp_query = []\n",
    "#             preliminary_kp_train = []\n",
    "\n",
    "#             for m,n in matches_preliminary:\n",
    "#                 if m.distance < N_DIST_COEFF_PRELIM*n.distance:\n",
    "#                     preliminary_kp_query.append(kp_query[m.trainIdx])\n",
    "#                     preliminary_kp_train.append(kp_train[m.queryIdx])\n",
    "\n",
    "#             ratio_scale_preliminary = []\n",
    "\n",
    "#             for entry_query,entry_train in zip(preliminary_kp_query,preliminary_kp_train):\n",
    "\n",
    "#                 ratio_scale_preliminary.append(entry_train.size / entry_query.size)          \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#             matches = flann.knnMatch(des_train,des_query,k=2)\n",
    "\n",
    "#             good_kp_query = []\n",
    "#             good_kp_train = []\n",
    "\n",
    "#             if query.shape[0] >= 200:\n",
    "#                 N_DIST_COEFF = 0.9\n",
    "#             if query.shape[0] >= 400:\n",
    "#                 N_DIST_COEFF = 0.8\n",
    "#             if query.shape[0] >= 600:\n",
    "#                 N_DIST_COEFF = 0.7\n",
    "\n",
    "#             for m,n in matches:\n",
    "#                 if m.distance < N_DIST_COEFF*n.distance:\n",
    "#                     good_kp_query.append(kp_query[m.trainIdx])\n",
    "#                     good_kp_train.append(kp_train[m.queryIdx])\n",
    "\n",
    "#             global_kp_query[query_img] = good_kp_query\n",
    "#             global_kp_train[query_img] = good_kp_train\n",
    "\n",
    "#             query_xc = np.mean(list(good_kp_query[i].pt[0] for i in range(len(good_kp_query))))\n",
    "#             query_yc = np.mean(list(good_kp_query[i].pt[1] for i in range(len(good_kp_query))))\n",
    "\n",
    "#             matches_4d = []\n",
    "\n",
    "#             for entry_query,entry_train in zip(good_kp_query,good_kp_train):\n",
    "\n",
    "#                 v = ((query_xc-entry_query.pt[0]), (query_yc-entry_query.pt[1]))\n",
    "#                 delta_angle = entry_train.angle - entry_query.angle\n",
    "#                 ratio_scale = entry_train.size / entry_query.size\n",
    "#                 train_xc = entry_train.pt[0] + ratio_scale * (np.cos(delta_angle) * v[0] - np.sin(delta_angle) * v[1])\n",
    "#                 train_yc = entry_train.pt[1] + ratio_scale * (np.sin(delta_angle) * v[0] + np.cos(delta_angle) * v[1])\n",
    "\n",
    "#                 matches_4d.append((train_xc,train_yc,delta_angle,ratio_scale))\n",
    "\n",
    "#             global_matches_4d[query_img] = matches_4d  \n",
    " \n",
    "#             ratio_scale_preliminary                 #?????\n",
    "\n",
    "#             counts_scale, bins_scale, patches_size = plt.hist(ratio_scale_preliminary,bins='auto')\n",
    "#             img_scale = np.mean([bins_scale[np.argmax(counts_scale)],bins_scale[np.argmax(counts_scale)+1]])\n",
    "#             plt.close();\n",
    "\n",
    "\n",
    "#             data_scale = list(matches_4d[i][3] for i in range(len(matches_4d)))\n",
    "#             counts_scale, bins_scale, patches_size = plt.hist(data_scale,bins='auto')\n",
    "#             plt.close();\n",
    "\n",
    "#             data_angle = list(matches_4d[i][2] for i in range(len(matches_4d)))\n",
    "#             counts_angle, bins_angle, patches_angle = plt.hist(data_angle,bins='auto')\n",
    "#             plt.close();\n",
    "\n",
    "#             x_bin_size = img_scale * query.shape[1] * BIN_PRECISION_FACTOR\n",
    "#             y_bin_size = img_scale * query.shape[0] * BIN_PRECISION_FACTOR\n",
    "#             x_bins = int(np.ceil(train.shape[1]/x_bin_size)+2)\n",
    "#             y_bins = int(np.ceil(train.shape[0]/y_bin_size)+2)\n",
    "#             x_min = train.shape[1]/2 - x_bins/2 * x_bin_size\n",
    "#             y_min = train.shape[0]/2 - y_bins/2 * y_bin_size\n",
    "#             x_max = train.shape[1]/2 + x_bins/2 * x_bin_size\n",
    "#             y_max = train.shape[0]/2 + y_bins/2 * y_bin_size\n",
    "\n",
    "\n",
    "#             angle_bin_size = np.std(data_angle)*ANGLE_BIN_SIZE_COEFF\n",
    "#             angle_bin_center = np.mean(data_angle)\n",
    "#             angle_min = angle_bin_center - ANGLE_BINS/2 * angle_bin_size\n",
    "#             angle_max = angle_bin_center + ANGLE_BINS/2 * angle_bin_size\n",
    "\n",
    "#             scale_bin_size = np.std(data_scale)*SCALE_BIN_SIZE_COEFF\n",
    "#             scale_bin_center = np.mean(data_scale)\n",
    "#             scale_min = 0 #scale_bin_center - SCALE_BINS/2 * scale_bin_size\n",
    "#             scale_max = scale_bin_center * 2 #scale_bin_center + SCALE_BINS/2 * scale_bin_size\n",
    "#             SCALE_BINS = int((scale_max-scale_min)/scale_bin_size)\n",
    "\n",
    "#             def votesOnMatch(m_4d):\n",
    "\n",
    "#                 accumulator = np.zeros((x_bins,y_bins,ANGLE_BINS,SCALE_BINS))\n",
    "#                 votes = {}\n",
    "\n",
    "#                 for m in m_4d:\n",
    "#                     try:\n",
    "#                         for x in range(0,2):\n",
    "#                             for y in range(0,2):\n",
    "#                                 for z in range(0,2):\n",
    "#                                     for w in range(0,2):                \n",
    "#                                         i = int(np.floor((m[0]-x_min+(x-1/2)*x_bin_size)/x_bin_size))\n",
    "#                                         j = int(np.floor((m[1]-y_min+(y-1/2)*y_bin_size)/y_bin_size))\n",
    "#                                         k = int(np.floor((m[2]-angle_min+(z-1/2)*angle_bin_size)/angle_bin_size))\n",
    "#                                         l = int(np.floor((m[3]-scale_min+(w-1/2)*scale_bin_size)/scale_bin_size))\n",
    "#                                         if i >= 0 and j >= 0 and k >= 0 and l >= 0:\n",
    "#                                             accumulator[i][j][k][l]+=1\n",
    "#                                             votes[(i,j,k,l)] = votes.get((i,j,k,l),[])\n",
    "#                                             votes[(i,j,k,l)].append(m)\n",
    "#                     except: pass\n",
    "\n",
    "#                 return accumulator,votes\n",
    "\n",
    "#             accumulator,votes=votesOnMatch(matches_4d)\n",
    "\n",
    "#             T = T_Q+int(query.shape[0]*T_M)\n",
    "\n",
    "#             a2 = accumulator\n",
    "#             mask=sk.local_maxima(a2)\n",
    "#             a2[mask!=1] = 0\n",
    "\n",
    "#             global_votes[query_img] = votes\n",
    "#             global_centers[query_img] = (query_xc,query_yc)\n",
    "\n",
    "#             votes_total += [a2[tuple(b)] for b in list(np.argwhere(a2>=T))]\n",
    "\n",
    "#             fb+=[(query_img,tuple(b)) for b in list(np.argwhere(a2>=T))]\n",
    "\n",
    "#         except:\n",
    "#             pass\n",
    "    \n",
    "#     found_bins = [x for _,x in sorted(zip(votes_total,fb))[::-1]]\n",
    "#     better_matches = []\n",
    "#     better_centers = []\n",
    "# #    print(found_bins)\n",
    "    \n",
    "#     for b in found_bins:\n",
    "#         matches = []\n",
    "#         ccc = []\n",
    "#         for i in range(len(global_matches_4d[b[0]])):\n",
    "#             if global_matches_4d[b[0]][i] in global_votes[b[0]][tuple(b[1])]:\n",
    "#                 matches.append((global_kp_query[b[0]][i],global_kp_train[b[0]][i]))\n",
    "#                 ccc.append((global_matches_4d[b[0]][i][0],global_matches_4d[b[0]][i][1]))\n",
    "#         better_matches.append((b[0],matches))\n",
    "#         better_centers.append(ccc)\n",
    "\n",
    "#     delta = []\n",
    "#     areas = []\n",
    "#     dimensions = []\n",
    "#     for j in range(len(better_matches)):\n",
    "#         try:\n",
    "#             train2 = cv2.cvtColor(train5,cv2.COLOR_GRAY2RGB)\n",
    "#             matches = better_matches[j]\n",
    "#             better_c = better_centers[j]\n",
    "#             file = 'models/'+matches[0]+'.jpg'\n",
    "#             query = cv2.imread(file,0)\n",
    "#             query2 = cv2.imread(file)\n",
    "#             query_color = query2.mean(axis=0).mean(axis=0)\n",
    "#             src_pts = np.float32([ m[0].pt for m in matches[1] ]).reshape(-1,1,2)\n",
    "#             dst_pts = np.float32([ m[1].pt for m in matches[1] ]).reshape(-1,1,2)\n",
    "#             M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "#             matchesMask = mask.ravel().tolist()\n",
    "#             h,w = query.shape\n",
    "#             pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    "#             dst = cv2.perspectiveTransform(pts,M)\n",
    "# #            print(np.float32(list(global_centers[matches[0]])).reshape(-1,1,2))\n",
    "#             new_center = cv2.perspectiveTransform(np.float32(list(global_centers[matches[0]])).reshape(-1,1,2),M)[0][0]\n",
    "#             x_minimum = int(max(np.min(dst,axis=0)[0][0],0))\n",
    "#             y_minimum = int(max(np.min(dst,axis=0)[0][1],0))\n",
    "#             x_maximum = int(min(np.max(dst,axis=0)[0][0],train.shape[1]))\n",
    "#             y_maximum = int(min(np.max(dst,axis=0)[0][1],train.shape[0]))\n",
    "\n",
    "            \n",
    "#             for ijk in range(NUM_EPOCHS):\n",
    "            \n",
    "#                 dst_pts2 = []\n",
    "#                 src_pts2 = []\n",
    "\n",
    "#     #            print(dst_pts)\n",
    "\n",
    "#                 for i in range(len(src_pts)):\n",
    "#                     if dst_pts[i][0][0] > x_minimum and dst_pts[i][0][0] < x_maximum\\\n",
    "#                     and dst_pts[i][0][1] > y_minimum and dst_pts[i][0][1] < y_maximum:\n",
    "#                         dst_pts2.append([dst_pts[i][0][0],dst_pts[i][0][1]])\n",
    "#                         src_pts2.append([src_pts[i][0][0],src_pts[i][0][1]])\n",
    "\n",
    "#     #            print(dst_pts2)\n",
    "\n",
    "#                 src_pts = np.float32(src_pts2).reshape(-1,1,2)\n",
    "#                 dst_pts = np.float32(dst_pts2).reshape(-1,1,2)\n",
    "            \n",
    "#             for pt in dst_pts:\n",
    "#                 cv2.circle(train2, (int(pt[0][0]),int(pt[0][1])), radius=3, color=(0, 191, 0), thickness=5)\n",
    "#             M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "#             matchesMask = mask.ravel().tolist()\n",
    "#             h,w = query.shape\n",
    "#             pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    "#             dst = cv2.perspectiveTransform(pts,M)\n",
    "# #            print(np.float32(list(global_centers[matches[0]])).reshape(-1,1,2))\n",
    "#             new_center = cv2.perspectiveTransform(np.float32(list(global_centers[matches[0]])).reshape(-1,1,2),M)[0][0]\n",
    "#             x_minimum = int(max(np.min(dst,axis=0)[0][0],0))\n",
    "#             y_minimum = int(max(np.min(dst,axis=0)[0][1],0))\n",
    "#             x_maximum = int(min(np.max(dst,axis=0)[0][0],train.shape[1]))\n",
    "#             y_maximum = int(min(np.max(dst,axis=0)[0][1],train.shape[0]))\n",
    "            \n",
    "#             dimensions.append(((x_maximum-x_minimum),(y_maximum-y_minimum)))\n",
    "#             delta.append(np.sqrt((x_minimum-x_maximum)**2+(y_minimum-y_maximum)**2))\n",
    "#             center = (int((x_maximum+x_minimum)/2),int((y_maximum+y_minimum)/2))\n",
    "#             train_crop = train[y_minimum:y_maximum,x_minimum:x_maximum]\n",
    "#             train_color = train_crop.mean(axis=0).mean(axis=0)\n",
    "#             draw_params = dict(matchColor = (0,0,0), # draw matches in green color\n",
    "#                            singlePointColor = None,\n",
    "#                            matchesMask = matchesMask, # draw only inliers\n",
    "#                            flags = 2)\n",
    "#             color_diff = abs(query_color-train_color)\n",
    "#             dist = []\n",
    "#             area = 0\n",
    "#             for i in range(3):\n",
    "#                 area += dst[i][0][0]*dst[i+1][0][1]-dst[i+1][0][0]*dst[i][0][1]\n",
    "#             area += dst[3][0][0]*dst[0][0][1]-dst[0][0][0]*dst[3][0][1]\n",
    "#             area = abs(area/2)\n",
    "#             areas.append(area)\n",
    "#             for c in centers:\n",
    "#                 dist.append(np.sqrt((center[0]-c[0])**2+(center[1]-c[1])**2))\n",
    "#             min_dist = float(\"inf\")\n",
    "#             if len(dist)>0:\n",
    "#                 min_dist = min(dist)\n",
    "# #                print(min_dist)\n",
    "#             if max(color_diff)<COLOR_T and min_dist > delta[0]*CONSISTENCY_COEFF\\\n",
    "#                 and area/areas[0] > AREA_MIN and area/areas[0] < AREA_MAX\\\n",
    "#                 and (x_maximum-x_minimum)/dimensions[0][0] > DIM_MIN and (x_maximum-x_minimum)/dimensions[0][0] < DIM_MAX\\\n",
    "#                 and (y_maximum-y_minimum)/dimensions[0][1] > DIM_MIN and (y_maximum-y_minimum)/dimensions[0][1] < DIM_MAX\\\n",
    "#                 and dst[0][0][0] < dst[3][0][0]\\\n",
    "#                 and dst[1][0][0] < dst[2][0][0]\\\n",
    "#                 and dst[0][0][1] < dst[1][0][1]\\\n",
    "#                 and dst[3][0][1] < dst[2][0][1]:\n",
    "#                 train2 = cv2.polylines(train2,[np.int32(dst)],True,(0,255,0),3, cv2.LINE_AA)\n",
    "#                 font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "#                 cv2.putText(train2, matches[0],\\\n",
    "#                         (int((x_maximum-x_minimum)/4+x_minimum),int((y_maximum-y_minimum)*0.67+y_minimum)),\\\n",
    "#                         font, 5, (0,127,255), 10, cv2.LINE_AA)\n",
    "#                 x_accu=[]\n",
    "#                 y_accu=[]\n",
    "#                 for b_c in better_c:\n",
    "#                     cv2.circle(train2, (int(b_c[0]),int(b_c[1])), radius=3, color=(127, 0, 127), thickness=5)\n",
    "#                     x_accu.append(b_c[0])\n",
    "#                     y_accu.append(b_c[1])\n",
    "#                 cv2.circle(train2, (int(np.mean(x_accu)),int(np.mean(y_accu))), radius=5, color=(255, 0, 255), thickness=15)\n",
    "#                 cv2.circle(train2, (int(new_center[0]),int(new_center[1])), radius=5, color=(255, 191, 0), thickness=10)\n",
    "# #                print(matches[0])\n",
    "#                 centers.append(center)\n",
    "#                 plt.imshow(train2),plt.show();\n",
    "#         except: pass\n",
    "# #    plt.figure(figsize = (15,10))\n",
    "# ##    plt.imshow(train2),plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "#query_imgs = ['0','1','11','19','24','25','26']\n",
    "query_imgs = ['0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','26']\n",
    "#train_imgs = ['scenes/e1.png','scenes/e2.png','scenes/e3.png','scenes/e4.png','scenes/e5.png','scenes/m1.png','scenes/m2.png','scenes/m3.png','scenes/m4.png','scenes/m5.png']\n",
    "train_imgs = ['scenes/h1.jpg']#,'scenes/h2.jpg','scenes/h3.jpg','scenes/h4.jpg','scenes/h5.jpg']\n",
    "for N_DIST_COEFF in [0.9,0.95,0.99]:\n",
    "    for BIN_PRECISION_FACTOR in [0.1,0.15,0.2]:\n",
    "        for T_Q in [3]:#,5,7]:\n",
    "            for CONSISTENCY_COEFF in [0.25,0.33,0.5]:\n",
    "                print(N_DIST_COEFF,BIN_PRECISION_FACTOR,T_Q,CONSISTENCY_COEFF)\n",
    "                for train_img in train_imgs:\n",
    "                    print(train_img)\n",
    "                    step_B(query_imgs, train_img)\n",
    "                print(\"\\n\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# PARAMETERS\n",
    "N_DIST_COEFF_PRELIM = 0.7\n",
    "DIM_MIN = 0.5\n",
    "DIM_MAX = 2\n",
    "AREA_MIN = 0.5\n",
    "AREA_MAX = 2\n",
    "N_DIST_COEFF = 0.95\n",
    "BIN_PRECISION_FACTOR = 0.33 #ottimizzato 0.25\n",
    "ANGLE_BINS = 7\n",
    "ANGLE_BIN_SIZE_COEFF = 0.1\n",
    "SCALE_BIN_SIZE_COEFF = 0.1\n",
    "NEIGH = 1\n",
    "NUM_EPOCHS = 2\n",
    "T_Q = 3 #5\n",
    "T_M = 0 #1/25\n",
    "THRESHOLD_Q = 200 #ottimizzato 200\n",
    "THRESHOLD_M = 1/3\n",
    "COLOR_T = 50\n",
    "CONSISTENCY_COEFF = 0.33"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "query_imgs = ['0','1','11','19','24','25','26']\n",
    "#query_imgs = ['0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','26']\n",
    "train_imgs = ['scenes/h1.jpg']\n",
    "for train_img in train_imgs:\n",
    "    step_B(query_imgs, train_img)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#STEP B\n",
    "query_imgs = ['0','1','11','19','24','25','26']\n",
    "#query_imgs = ['0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','26']\n",
    "train_imgs = ['scenes/m1.png','scenes/m2.png','scenes/m3.png','scenes/m4.png','scenes/m5.png']\n",
    "for train_img in train_imgs:\n",
    "    step_B(query_imgs, train_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}