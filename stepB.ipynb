{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd \n",
    "import skimage.morphology as sk\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "N_DIST_COEFF_PRELIM = 0.7\n",
    "DIM_MIN = 0.5\n",
    "DIM_MAX = 2\n",
    "AREA_MIN = 0.5\n",
    "AREA_MAX = 2\n",
    "N_DIST_COEFF = 0.9\n",
    "BIN_PRECISION_FACTOR = 0.25 #ottimizzato 0.25\n",
    "ANGLE_BINS = 7\n",
    "ANGLE_BIN_SIZE_COEFF = 0.1\n",
    "SCALE_BIN_SIZE_COEFF = 0.1\n",
    "NEIGH = 1\n",
    "NUM_EPOCHS = 2\n",
    "T_Q = 5 #5\n",
    "T_M = 0 #1/25\n",
    "THRESHOLD_Q = 200 #ottimizzato 200\n",
    "THRESHOLD_M = 1/3\n",
    "COLOR_T = 50\n",
    "CONSISTENCY_COEFF = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_all_keypoints():\n",
    "\n",
    "    image_dict = {}\n",
    "\n",
    "    for img in query_imgs:\n",
    "        file = 'models/'+img+'.jpg'\n",
    "        query = cv2.imread(file,0)\n",
    "        kp, des = sift.detectAndCompute(query,None)\n",
    "        image_dict[img] = {'kp': kp,'des': des,'shape': query.shape}\n",
    "\n",
    "    for img in train_imgs:\n",
    "        file = 'scenes/'+img+'.png'\n",
    "        train = cv2.imread(file,0)\n",
    "        kp, des = sift.detectAndCompute(train,None)\n",
    "        image_dict[img] = {'kp': kp,'des': des, 'shape': train.shape}\n",
    "\n",
    "    return image_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_ratio_test(all_matches,coeff):\n",
    "\n",
    "    good_matches = {}      #map of matches kp_train_idx -> kp_query_idx\n",
    "    \n",
    "    for m,n in all_matches:\n",
    "        if m.distance < coeff*n.distance:\n",
    "            good_matches[m.queryIdx]= m.trainIdx\n",
    "\n",
    "\n",
    "    return good_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_entry_hough_space(kp_q,kp_t,q_xc,q_yc):\n",
    "\n",
    "    entry = {}\n",
    "\n",
    "    v = ((q_xc-kp_q.pt[0]), (q_yc-kp_q.pt[1]))\n",
    "    scale_ratio = kp_t.size/kp_q.size\n",
    "    delta_angle = kp_t.angle-kp_q.angle\n",
    "    x_c = kp_t.pt[0] + scale_ratio * (np.cos(delta_angle) * v[0] - np.sin(delta_angle) * v[1])\n",
    "    y_c = kp_t.pt[1] + scale_ratio * (np.sin(delta_angle) * v[0] + np.cos(delta_angle) * v[1])\n",
    "\n",
    "    entry['x_c']= x_c\n",
    "    entry['y_c']= y_c\n",
    "    entry['scale_ratio'] = scale_ratio\n",
    "    entry['delta_angle'] = delta_angle\n",
    "   \n",
    "\n",
    "    return entry "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hough_space(good_matches,kp_query,kp_train,query_xc,query_yc):\n",
    "    \n",
    "    hough_space = {}     #map of hough space kp_train_idx -> map name-values\n",
    "\n",
    "    for t_idx,q_idx in good_matches.items():\n",
    "        hough_space[t_idx] = compute_entry_hough_space(kp_query[q_idx],kp_train[t_idx],query_xc,query_yc)\n",
    "    \n",
    "    return hough_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bins(hough_space,query_shape,train_shape):\n",
    "\n",
    "    values = {}\n",
    "    \n",
    "    data_scale = [entry['scale_ratio'] for entry in hough_space.values()]\n",
    "    counts_scale, bins_scale, patches_size = plt.hist(data_scale,bins='auto')\n",
    "    img_scale = np.mean([bins_scale[np.argmax(counts_scale)],bins_scale[np.argmax(counts_scale)+1]])\n",
    "    plt.close();\n",
    "\n",
    "    data_angle = [entry['delta_angle'] for entry in hough_space.values()]\n",
    "    counts_angle, bins_angle, patches_angle = plt.hist(data_angle,bins='auto')\n",
    "    plt.close();\n",
    "\n",
    "    x_bin_size = img_scale * query_shape[1] * BIN_PRECISION_FACTOR\n",
    "    y_bin_size = img_scale * query_shape[0] * BIN_PRECISION_FACTOR\n",
    "    x_bins = int(np.ceil(train_shape[1]/x_bin_size)+2)\n",
    "    y_bins = int(np.ceil(train_shape[0]/y_bin_size)+2)\n",
    "    x_min = train_shape[1]/2 - x_bins/2 * x_bin_size\n",
    "    y_min = train_shape[0]/2 - y_bins/2 * y_bin_size\n",
    "\n",
    "    angle_bin_size = np.std(data_angle)*ANGLE_BIN_SIZE_COEFF\n",
    "    angle_bin_center = np.mean(data_angle)\n",
    "    angle_min = angle_bin_center - ANGLE_BINS/2 * angle_bin_size\n",
    "    angle_max = angle_bin_center + ANGLE_BINS/2 * angle_bin_size\n",
    "\n",
    "    scale_bin_size = np.std(data_scale)*SCALE_BIN_SIZE_COEFF\n",
    "    scale_bin_center = np.mean(data_scale)\n",
    "    scale_min = 0 \n",
    "    scale_max = scale_bin_center * 2 \n",
    "    scale_bins = int((scale_max-scale_min)/scale_bin_size)\n",
    "\n",
    "    values['x_bins'] = x_bins\n",
    "    values['y_bins'] = y_bins\n",
    "    values['x_min'] = x_min\n",
    "    values['y_min'] = y_min\n",
    "    values['x_bin_size'] = x_bin_size\n",
    "    values['y_bin_size'] = y_bin_size\n",
    "    values['scale_bins'] = scale_bins\n",
    "    values['scale_min'] = scale_min\n",
    "    values['scale_bin_size'] = scale_bin_size\n",
    "    values['angle_min'] = angle_min\n",
    "    values['angle_bin_size'] = angle_bin_size \n",
    "\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voting(b,h_s):\n",
    "\n",
    "    accumulator = np.zeros((b['x_bins'],b['y_bins'],ANGLE_BINS,b['scale_bins']))\n",
    "\n",
    "    votes = {}\n",
    "\n",
    "    for idx,v in h_s.items():\n",
    "        try:\n",
    "            for x in range(0,2):\n",
    "                for y in range(0,2):\n",
    "                    for z in range(0,2):\n",
    "                        for w in range(0,2):                \n",
    "                            i = int(np.floor((v['x_c']-b['x_min']+(x-1/2)*b['x_bin_size'])/b['x_bin_size']))\n",
    "                            j = int(np.floor((v['y_c']-b['y_min']+(y-1/2)*b['y_bin_size'])/b['y_bin_size']))\n",
    "                            k = int(np.floor((v['delta_angle']-b['angle_min']+(z-1/2)*b['angle_bin_size'])/b['angle_bin_size']))\n",
    "                            l = int(np.floor((v['scale_ratio']-b['scale_min']+(w-1/2)*b['scale_bin_size'])/b['scale_bin_size']))\n",
    "                            if i >= 0 and j >= 0 and k >= 0 and l >= 0:\n",
    "                                accumulator[i][j][k][l]+=1\n",
    "                                votes[(i,j,k,l)] = votes.get((i,j,k,l),[])\n",
    "                                votes[(i,j,k,l)].append(idx)\n",
    "        except: pass\n",
    "    \n",
    "    return accumulator,votes\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_imgs = ['0','1','11','19','24','25','26']\n",
    "train_imgs = ['e1','e2','e3','e4','e5','m1','m2','m3','m4','m5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_B(query_imgs, train_img, image_dict):\n",
    "\n",
    "    global_correspondences = []\n",
    "    recognised = {}\n",
    "\n",
    "    for query_img in query_imgs:\n",
    "\n",
    "        kp_query, des_query = image_dict[query_img]['kp'], image_dict[query_img]['des']\n",
    "        kp_train, des_train = image_dict[train_img]['kp'], image_dict[train_img]['des']\n",
    "\n",
    "        all_matches = bf.knnMatch(des_train, des_query, k=2)\n",
    "\n",
    "        if image_dict[query_img]['shape'][0] >= 200:\n",
    "            N_DIST_COEFF = 0.9\n",
    "        if image_dict[query_img]['shape'][0] >= 400:\n",
    "            N_DIST_COEFF = 0.8\n",
    "        if image_dict[query_img]['shape'][0] >= 600:\n",
    "            N_DIST_COEFF = 0.7\n",
    "\n",
    "        #map of matching keypoint indexes\n",
    "        good_matches = apply_ratio_test(all_matches, N_DIST_COEFF)\n",
    "\n",
    "        #barycenter of found query keypoint \n",
    "        query_xc = np.mean(list(kp_query[p].pt[0] for _,p in good_matches.items()))\n",
    "        query_yc = np.mean(list(kp_query[p].pt[1] for _,p in good_matches.items()))\n",
    "\n",
    "        #create hough space \n",
    "        hough_space = create_hough_space(good_matches,kp_query,kp_train,query_xc,query_yc)\n",
    "\n",
    "        #compute all the values related to the size \n",
    "        bins_values = compute_bins(hough_space,image_dict[query_img]['shape'],image_dict[train_img]['shape'])\n",
    "\n",
    "        #create and populate accumulator with voting by each entry of the hough space \n",
    "        accumulator,votes= voting(bins_values,hough_space)\n",
    "\n",
    "        #compute local maxima of the 4d accumulator \n",
    "        mask=sk.local_maxima(accumulator)\n",
    "        accumulator[mask!=1] = 0\n",
    "\n",
    "        #store in a list all the correspondeces between query points and train points that voted for a local maxima \n",
    "            #the list contain: number of votes that a local maxima bin has received, name of query                                                                                                   image, list of query and train keypoints which voted for that bin \n",
    "\n",
    "        T = T_Q+int(image_dict[query_img]['shape'][0]*T_M)               #threhsold to come up with few maxima \n",
    "\n",
    "        for b in list(np.argwhere(accumulator>=T)):\n",
    "            keypoint_index_list = votes[tuple(b)]       #all query keypoint who voted for a local maxima bin \n",
    "            correspondence_list = [(kp_train[k],kp_query[good_matches[k]]) for k in keypoint_index_list]\n",
    "            global_correspondences.append([accumulator[tuple(b)],query_img,correspondence_list])\n",
    "\n",
    "    g_c = sorted(global_correspondences, key=itemgetter(0), reverse=True )    #sorted correspondences based on number of votes found in local maxima bins \n",
    "\n",
    "    \n",
    "    train_file = 'scenes/' + train_img + '.png'\n",
    "    train = cv2.imread(train_file, 0)              \n",
    "    train_rgb = cv2.cvtColor(train, cv2.COLOR_GRAY2RGB)\n",
    "    train_bgr = cv2.imread(train_file)\n",
    "\n",
    "    areas = []\n",
    "\n",
    "    #qui ci va un commento \n",
    "    for entry in g_c:\n",
    "        try:\n",
    " \n",
    "            query_file = 'models/'+entry[1]+'.jpg'\n",
    "            query_bgr = cv2.imread(query_file)\n",
    "            \n",
    "            src_pts = np.float32([e[1].pt for e in entry[2]]).reshape(-1, 1, 2)\n",
    "            dst_pts = np.float32([e[0].pt for e in entry[2]]).reshape(-1, 1, 2)\n",
    "            M, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "            h, w, d = query_bgr.shape\n",
    "            pts = np.float32([[0,0],[0,h-1],[w-1,h-1],[w-1,0]]).reshape(-1,1,2)\n",
    "            dst = cv2.perspectiveTransform(pts, M)\n",
    "        \n",
    "            # center = tuple((dst[0,0,i] + dst[1,0,i] + dst[2,0,i] + dst[3,0,i]) / 4 for i in (0,1))\n",
    "                                  \n",
    "            x_min = int(max((dst[0,0,0] + dst[1,0,0]) / 2, 0))\n",
    "            y_min = int(max((dst[0,0,1] + dst[3,0,1]) / 2, 0))\n",
    "            x_max = int(min((dst[2,0,0] + dst[3,0,0]) / 2, train_bgr.shape[1]))\n",
    "            y_max = int(min((dst[1,0,1] + dst[2,0,1]) / 2, train_bgr.shape[0]))\n",
    "\n",
    "\n",
    "            for _ in range(NUM_EPOCHS):\n",
    "            \n",
    "                dst_pts2 = []\n",
    "                src_pts2 = []\n",
    "\n",
    "                for i in range(len(src_pts)):\n",
    "                    if dst_pts[i][0][0] > x_min and dst_pts[i][0][0] < x_max\\\n",
    "                    and dst_pts[i][0][1] > y_min and dst_pts[i][0][1] < y_max:\n",
    "                        dst_pts2.append([dst_pts[i][0][0],dst_pts[i][0][1]])\n",
    "                        src_pts2.append([src_pts[i][0][0],src_pts[i][0][1]])\n",
    "\n",
    "                src_pts = np.float32(src_pts2).reshape(-1,1,2)\n",
    "                dst_pts = np.float32(dst_pts2).reshape(-1,1,2)\n",
    "\n",
    "            dst = cv2.perspectiveTransform(pts, M)\n",
    "        \n",
    "            center = tuple((dst[0,0,i] + dst[1,0,i] + dst[2,0,i] + dst[3,0,i]) / 4 for i in (0,1))\n",
    "                                  \n",
    "            x_min = int(max((dst[0,0,0] + dst[1,0,0]) / 2, 0))\n",
    "            y_min = int(max((dst[0,0,1] + dst[3,0,1]) / 2, 0))\n",
    "            x_max = int(min((dst[2,0,0] + dst[3,0,0]) / 2, train_bgr.shape[1]))\n",
    "            y_max = int(min((dst[1,0,1] + dst[2,0,1]) / 2, train_bgr.shape[0]))\n",
    "\n",
    "\n",
    "\n",
    "            query_color = query_bgr.mean(axis=0).mean(axis=0)\n",
    "            train_crop = train_bgr[y_min:y_max,x_min:x_max]\n",
    "            train_color = train_crop.mean(axis=0).mean(axis=0)   \n",
    "            color_diff = np.sqrt(np.sum([value ** 2 for value in abs(query_color - train_color)]))\n",
    "        \n",
    "\n",
    "            area = 0\n",
    "            for i in range(3):\n",
    "                area += dst[i][0][0]*dst[i+1][0][1]-dst[i+1][0][0]*dst[i][0][1]\n",
    "            area += dst[3][0][0]*dst[0][0][1]-dst[0][0][0]*dst[3][0][1]\n",
    "            area = abs(area/2)\n",
    "            areas.append(area)\n",
    "\n",
    "            temp = True \n",
    "            if color_diff < COLOR_T and area/areas[0] > AREA_MIN and area/areas[0] < AREA_MAX\\\n",
    "                and dst[0][0][0] < dst[3][0][0]\\\n",
    "                and dst[1][0][0] < dst[2][0][0]\\\n",
    "                and dst[0][0][1] < dst[1][0][1]\\\n",
    "                and dst[3][0][1] < dst[2][0][1]:\n",
    "                for k, v in recognised.items():\n",
    "                    for corners in v:\n",
    "                        if center[0] > corners[0,0,0] and center[0] < corners[3,0,0]\\\n",
    "                            and center[1] > corners[0,0,1] and center[1] < corners[1,0,1]:\n",
    "                            temp = False\n",
    "                            break\n",
    "                if temp:\n",
    "                    recognised[entry[1]] = recognised.get(entry[1],[])  \n",
    "                    recognised[entry[1]].append(dst)\n",
    "                    print(entry[1])\n",
    "        except: pass\n",
    "\n",
    "\n",
    "    for k, v in recognised.items():\n",
    "        for dst in v:\n",
    "            \n",
    "            train_rgb = cv2.polylines(train_rgb, [np.int32(dst)], True, (0,255,0), 3, cv2.LINE_AA)\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            #cv2.putText(train_rgb, k,\\\n",
    "                            #(int((v[3][0][0] - v[00,0]) * 0.25 + v[0,0,0]),int((v[1,0,1] - v[0,0,1]) * 0.67 + v[0,0,1])),\\\n",
    "                            #font, 5, (0,255,0), 10, cv2.LINE_AA)        \n",
    "            \n",
    "        \n",
    "    plt.imshow(train_rgb),plt.show();\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "bf = cv2.BFMatcher()\n",
    "\n",
    "image_dict = compute_all_keypoints()\n",
    "\n",
    "for train_img in train_imgs:\n",
    "\n",
    "    step_B(query_imgs, train_img,image_dict)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# areas = []\n",
    "#     dimensions = []\n",
    "#     delta = []\n",
    "#     centers = []\n",
    "#     for j in range(len(g_c)):\n",
    "#         try:\n",
    "#             train2 = cv2.cvtColor(train,cv2.COLOR_GRAY2RGB)\n",
    "#             matches = g_c[j]\n",
    "#             better_c = g_c[j]\n",
    "#             file = 'models/'+matches[1]+'.jpg'\n",
    "#             query = cv2.imread(file,0)\n",
    "#             query2 = cv2.imread(file)\n",
    "#             query_color = query2.mean(axis=0).mean(axis=0)\n",
    "#             src_pts = np.float32([ m[1].pt for m in matches[2] ]).reshape(-1,1,2)\n",
    "#             dst_pts = np.float32([ m[0].pt for m in matches[2] ]).reshape(-1,1,2)\n",
    "#             M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "#             matchesMask = mask.ravel().tolist()\n",
    "#             h,w = query.shape\n",
    "#             pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    "#             dst = cv2.perspectiveTransform(pts,M)\n",
    "# #            print(np.float32(list(global_centers[matches[0]])).reshape(-1,1,2))\n",
    "#             #new_center = cv2.perspectiveTransform(np.float32(list(global_centers[matches[0]])).reshape(-1,1,2),M)[0][0]\n",
    "#             x_minimum = int(max(np.min(dst,axis=0)[0][0],0))\n",
    "#             y_minimum = int(max(np.min(dst,axis=0)[0][1],0))\n",
    "#             x_maximum = int(min(np.max(dst,axis=0)[0][0],train.shape[1]))\n",
    "#             y_maximum = int(min(np.max(dst,axis=0)[0][1],train.shape[0]))\n",
    "\n",
    "            \n",
    "#             for ijk in range(NUM_EPOCHS):\n",
    "            \n",
    "#                 dst_pts2 = []\n",
    "#                 src_pts2 = []\n",
    "\n",
    "#     #            print(dst_pts)\n",
    "\n",
    "#                 for i in range(len(src_pts)):\n",
    "#                     if dst_pts[i][0][0] > x_minimum and dst_pts[i][0][0] < x_maximum\\\n",
    "#                     and dst_pts[i][0][1] > y_minimum and dst_pts[i][0][1] < y_maximum:\n",
    "#                         dst_pts2.append([dst_pts[i][0][0],dst_pts[i][0][1]])\n",
    "#                         src_pts2.append([src_pts[i][0][0],src_pts[i][0][1]])\n",
    "\n",
    "#     #            print(dst_pts2)\n",
    "\n",
    "#                 src_pts = np.float32(src_pts2).reshape(-1,1,2)\n",
    "#                 dst_pts = np.float32(dst_pts2).reshape(-1,1,2)\n",
    "            \n",
    "            \n",
    "#             M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "#             matchesMask = mask.ravel().tolist()\n",
    "#             h,w = query.shape\n",
    "#             pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    "#             dst = cv2.perspectiveTransform(pts,M)\n",
    "# #            print(np.float32(list(global_centers[matches[0]])).reshape(-1,1,2))\n",
    "#             #new_center = cv2.perspectiveTransform(np.float32(list(global_centers[matches[0]])).reshape(-1,1,2),M)[0][0]\n",
    "#             x_minimum = int(max(np.min(dst,axis=0)[0][0],0))\n",
    "#             y_minimum = int(max(np.min(dst,axis=0)[0][1],0))\n",
    "#             x_maximum = int(min(np.max(dst,axis=0)[0][0],train.shape[1]))\n",
    "#             y_maximum = int(min(np.max(dst,axis=0)[0][1],train.shape[0]))\n",
    "            \n",
    "#             dimensions.append(((x_maximum-x_minimum),(y_maximum-y_minimum)))\n",
    "#             delta.append(np.sqrt((x_minimum-x_maximum)**2+(y_minimum-y_maximum)**2))\n",
    "#             center = (int((x_maximum+x_minimum)/2),int((y_maximum+y_minimum)/2))\n",
    "#             train_crop = train[y_minimum:y_maximum,x_minimum:x_maximum]\n",
    "#             train_color = train_crop.mean(axis=0).mean(axis=0)\n",
    "#             draw_params = dict(matchColor = (0,0,0), # draw matches in green color\n",
    "#                            singlePointColor = None,\n",
    "#                            matchesMask = matchesMask, # draw only inliers\n",
    "#                            flags = 2)\n",
    "#             color_diff = abs(query_color-train_color)\n",
    "#             dist = []\n",
    "#             area = 0\n",
    "#             for i in range(3):\n",
    "#                 area += dst[i][0][0]*dst[i+1][0][1]-dst[i+1][0][0]*dst[i][0][1]\n",
    "#             area += dst[3][0][0]*dst[0][0][1]-dst[0][0][0]*dst[3][0][1]\n",
    "#             area = abs(area/2)\n",
    "#             areas.append(area)\n",
    "#             for c in centers:\n",
    "#                 dist.append(np.sqrt((center[0]-c[0])**2+(center[1]-c[1])**2))\n",
    "#             min_dist = float(\"inf\")\n",
    "#             if len(dist)>0:\n",
    "#                 min_dist = min(dist)\n",
    "# #                print(min_dist)\n",
    "#             if max(color_diff)<COLOR_T and min_dist > delta[0]*CONSISTENCY_COEFF\\\n",
    "#                 and area/areas[0] > AREA_MIN and area/areas[0] < AREA_MAX\\\n",
    "#                 and (x_maximum-x_minimum)/dimensions[0][0] > DIM_MIN and (x_maximum-x_minimum)/dimensions[0][0] < DIM_MAX\\\n",
    "#                 and (y_maximum-y_minimum)/dimensions[0][1] > DIM_MIN and (y_maximum-y_minimum)/dimensions[0][1] < DIM_MAX\\\n",
    "#                 and dst[0][0][0] < dst[3][0][0]\\\n",
    "#                 and dst[1][0][0] < dst[2][0][0]\\\n",
    "#                 and dst[0][0][1] < dst[1][0][1]\\\n",
    "#                 and dst[3][0][1] < dst[2][0][1]:\n",
    "#                 train2 = cv2.polylines(train2,[np.int32(dst)],True,(0,255,0),3, cv2.LINE_AA)\n",
    "#                 font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "#                 cv2.putText(train2, matches[1],\\\n",
    "#                         (int((x_maximum-x_minimum)/4+x_minimum),int((y_maximum-y_minimum)*0.67+y_minimum)),\\\n",
    "#                         font, 5, (0,127,255), 10, cv2.LINE_AA)\n",
    "                \n",
    "#                 centers.append(center)\n",
    "#                 plt.imshow(train2),plt.show();\n",
    "#         except: pass\n",
    "# #    plt.figure(figsize = (15,10))\n",
    "# ##    plt.imshow(train2),plt.show();\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "#query_imgs = ['0','1','11','19','24','25','26']\n",
    "query_imgs = ['0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','26']\n",
    "#train_imgs = ['scenes/e1.png','scenes/e2.png','scenes/e3.png','scenes/e4.png','scenes/e5.png','scenes/m1.png','scenes/m2.png','scenes/m3.png','scenes/m4.png','scenes/m5.png']\n",
    "train_imgs = ['scenes/h1.jpg']#,'scenes/h2.jpg','scenes/h3.jpg','scenes/h4.jpg','scenes/h5.jpg']\n",
    "for N_DIST_COEFF in [0.9,0.95,0.99]:\n",
    "    for BIN_PRECISION_FACTOR in [0.1,0.15,0.2]:\n",
    "        for T_Q in [3]:#,5,7]:\n",
    "            for CONSISTENCY_COEFF in [0.25,0.33,0.5]:\n",
    "                print(N_DIST_COEFF,BIN_PRECISION_FACTOR,T_Q,CONSISTENCY_COEFF)\n",
    "                for train_img in train_imgs:\n",
    "                    print(train_img)\n",
    "                    step_B(query_imgs, train_img)\n",
    "                print(\"\\n\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# PARAMETERS\n",
    "N_DIST_COEFF_PRELIM = 0.7\n",
    "DIM_MIN = 0.5\n",
    "DIM_MAX = 2\n",
    "AREA_MIN = 0.5\n",
    "AREA_MAX = 2\n",
    "N_DIST_COEFF = 0.95\n",
    "BIN_PRECISION_FACTOR = 0.33 #ottimizzato 0.25\n",
    "ANGLE_BINS = 7\n",
    "ANGLE_BIN_SIZE_COEFF = 0.1\n",
    "SCALE_BIN_SIZE_COEFF = 0.1\n",
    "NEIGH = 1\n",
    "NUM_EPOCHS = 2\n",
    "T_Q = 3 #5\n",
    "T_M = 0 #1/25\n",
    "THRESHOLD_Q = 200 #ottimizzato 200\n",
    "THRESHOLD_M = 1/3\n",
    "COLOR_T = 50\n",
    "CONSISTENCY_COEFF = 0.33"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "query_imgs = ['0','1','11','19','24','25','26']\n",
    "#query_imgs = ['0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','26']\n",
    "train_imgs = ['scenes/h1.jpg']\n",
    "for train_img in train_imgs:\n",
    "    step_B(query_imgs, train_img)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#STEP B\n",
    "query_imgs = ['0','1','11','19','24','25','26']\n",
    "#query_imgs = ['0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','26']\n",
    "train_imgs = ['scenes/m1.png','scenes/m2.png','scenes/m3.png','scenes/m4.png','scenes/m5.png']\n",
    "for train_img in train_imgs:\n",
    "    step_B(query_imgs, train_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
